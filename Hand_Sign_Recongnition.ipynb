{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning-Sign Language Digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "### Deep learning is one of the Machine Learning techniques that learns features directly from data.When the amount of data is increased, machine learning techniques are insufficient in terms of performance and deep learning gives better performance like accuracy. Depp Learning also gives better accuracy than Machine Learning when the complexity of the problem also increases like Speech Recognition, Image Classification, Natural Language Processing and so on\n",
    "### In this project the sign language digits data set is used. There are 2062 image samples with hand signs from 0 to 9 totaling 10 different hand signs present in the dataset.\n",
    "### The Concepts of Convolutional Neural Networks(CNN) and Artificial Neural Network(ANN) are both implemented here.\n",
    "### The various parameters of the Deep Learning models in both the CNN and ANN are indeed varied and the accuracy is noted for each case and also how the network plateaus for the particular value and how it is deviated with regards to the network plateau is also noted.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Importing the necessary libraries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Input, Conv2D, MaxPooling2D, BatchNormalization#For CNN\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "# Handle the warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from subprocess import check_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape : (2062, 64, 64)  Y shape: (2062, 10)\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Loading the Data Set\n",
    "X = np.load('X.npy')\n",
    "y = np.load('Y.npy')\n",
    "print('X shape : {}  Y shape: {}'.format(X.shape, y.shape))\n",
    "\n",
    "plt.imshow(X[700], cmap='gray')\n",
    "print(y[700])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2312e1a3c48>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[2000]) #Showing a particualr instance of the dataset as to what sign of the image set is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 63.5, 63.5, -0.5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Reshape the images of the signs 0 and 1 and see it visually\n",
    "img_size = 64\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(X[260].reshape(img_size, img_size))\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(X[900].reshape(img_size, img_size))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split test and train\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=8)\n",
    "# add another axis representing grey-scale\n",
    "Xtest = Xtest[:,:,:,np.newaxis]\n",
    "Xtrain=Xtrain[:,:,:,np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN(Convolutional Neural Network)\n",
    "### A Convolutional neural network is a class of deep neural networks,that has one or more Convolutional Layers(a simple filter to an input that results in activation) most commonly applied to analyzing visual imagery. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Designing the Convolutional Models. The base model on this analysis is considered as the one where netowrk plateaus as in the accuracy does not increase further with the standard model varying the features like epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Very first CNN model having the 32 filters with Kernel Size of 5,5 and having an activation funciton of relu and a network initialization of Xavier Uniform\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (5, 5), activation='relu', kernel_initializer='glorot_uniform', bias_initializer='zeros'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',#The model is then compiled and we see that the cost function(loss component is of cross entropy and the gradient estimation of ADA delta is used inititally)\n",
    "             optimizer='adadelta',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1649 samples\n",
      "1649/1649 [==============================] - 9s 6ms/sample - loss: 2.6168 - accuracy: 0.0934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x231320bbcc8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain, ytrain, batch_size=32, epochs=1)# With an epoch value of 1 the accuracy is 0.09 which is not good "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(Xtest, ytest, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.3025  Accuaracy: 0.09685\n"
     ]
    }
   ],
   "source": [
    "print('Loss: {:.4f}  Accuaracy: {:.4}'.format(score[0],score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1649 samples\n",
      "Epoch 1/2\n",
      "1649/1649 [==============================] - 9s 5ms/sample - loss: 2.4192 - accuracy: 0.1474\n",
      "Epoch 2/2\n",
      "1649/1649 [==============================] - 9s 5ms/sample - loss: 2.3110 - accuracy: 0.1747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2312e137d88>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain, ytrain, batch_size=32, epochs=2)# General model for computation with epoch=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(Xtest, ytest, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.2682  Accuaracy: 0.2082\n"
     ]
    }
   ],
   "source": [
    "print('Loss: {:.4f}  Accuaracy: {:.4}'.format(score[0],score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3 \n",
    "#### Has epoch =3 and the accuracy is still not plateaued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1649 samples\n",
      "Epoch 1/3\n",
      "1649/1649 [==============================] - 9s 5ms/sample - loss: 2.2381 - accuracy: 0.1989\n",
      "Epoch 2/3\n",
      "1649/1649 [==============================] - 9s 5ms/sample - loss: 2.1413 - accuracy: 0.2244\n",
      "Epoch 3/3\n",
      "1649/1649 [==============================] - 9s 5ms/sample - loss: 2.0554 - accuracy: 0.2662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x231382764c8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain, ytrain, batch_size=32, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(Xtest, ytest, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.1582  Accuaracy: 0.3971\n"
     ]
    }
   ],
   "source": [
    "print('Loss: {:.4f}  Accuaracy: {:.4}'.format(score[0],score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1649 samples\n",
      "Epoch 1/4\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 2.0068 - accuracy: 0.2978\n",
      "Epoch 2/4\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 1.9096 - accuracy: 0.3451\n",
      "Epoch 3/4\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 1.8473 - accuracy: 0.3566\n",
      "Epoch 4/4\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 1.7918 - accuracy: 0.3893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23138335748>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain, ytrain, batch_size=32, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(Xtest, ytest, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.8359  Accuaracy: 0.5133\n"
     ]
    }
   ],
   "source": [
    "print('Loss: {:.4f}  Accuaracy: {:.4}'.format(score[0],score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1649 samples\n",
      "Epoch 1/6\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 1.7285 - accuracy: 0.4142\n",
      "Epoch 2/6\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 1.6872 - accuracy: 0.4500\n",
      "Epoch 3/6\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 1.6474 - accuracy: 0.4536\n",
      "Epoch 4/6\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 1.6092 - accuracy: 0.4560\n",
      "Epoch 5/6\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 1.5761 - accuracy: 0.4669\n",
      "Epoch 6/6\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 1.5095 - accuracy: 0.4985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23138439a88>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain, ytrain, batch_size=32, epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(Xtest, ytest, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.4060  Accuaracy: 0.5981\n"
     ]
    }
   ],
   "source": [
    "print('Loss: {:.4f}  Accuaracy: {:.4}'.format(score[0],score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 6 (Base Model)\n",
    "#### This is considered as the based model with an epoch value=10 and also the network plateau is reached as the accuracy does not vary much and is in the range of 0.7 itself when the epochs are increased again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1649 samples\n",
      "Epoch 1/10\n",
      "1649/1649 [==============================] - 11s 6ms/sample - loss: 1.4863 - accuracy: 0.5112\n",
      "Epoch 2/10\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 1.4415 - accuracy: 0.5306\n",
      "Epoch 3/10\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 1.4131 - accuracy: 0.5367\n",
      "Epoch 4/10\n",
      "1649/1649 [==============================] - 12s 7ms/sample - loss: 1.3913 - accuracy: 0.5452\n",
      "Epoch 5/10\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 1.3651 - accuracy: 0.5525\n",
      "Epoch 6/10\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 1.3167 - accuracy: 0.5706\n",
      "Epoch 7/10\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 1.2768 - accuracy: 0.5882\n",
      "Epoch 8/10\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 1.2730 - accuracy: 0.5870\n",
      "Epoch 9/10\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 1.2319 - accuracy: 0.6010\n",
      "Epoch 10/10\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 1.2389 - accuracy: 0.6095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23138512e08>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain, ytrain, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(Xtest, ytest, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.1324  Accuaracy: 0.6998\n"
     ]
    }
   ],
   "source": [
    "print('Loss: {:.4f}  Accuaracy: {:.4}'.format(score[0],score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 7\n",
    "#### Same accuracy almost of 0.7 even with epochs=20 as the one with epoch=10. Designed to verify the network plateau for the model beyond a certain epoch point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1649 samples\n",
      "Epoch 1/20\n",
      "1649/1649 [==============================] - 11s 6ms/sample - loss: 1.1921 - accuracy: 0.6307\n",
      "Epoch 2/20\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 1.1589 - accuracy: 0.6301\n",
      "Epoch 3/20\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 1.1484 - accuracy: 0.6289\n",
      "Epoch 4/20\n",
      "1649/1649 [==============================] - 12s 7ms/sample - loss: 1.1383 - accuracy: 0.6361\n",
      "Epoch 5/20\n",
      "1649/1649 [==============================] - 12s 7ms/sample - loss: 1.1181 - accuracy: 0.6574\n",
      "Epoch 6/20\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 1.0913 - accuracy: 0.6519\n",
      "Epoch 7/20\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 1.0840 - accuracy: 0.6562\n",
      "Epoch 8/20\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 1.0502 - accuracy: 0.6562\n",
      "Epoch 9/20\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 1.0442 - accuracy: 0.6731\n",
      "Epoch 10/20\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 1.0359 - accuracy: 0.6677s - loss: 1.0825 - ac - ETA: 2s -\n",
      "Epoch 11/20\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 1.0034 - accuracy: 0.6865\n",
      "Epoch 12/20\n",
      "1649/1649 [==============================] - 12s 8ms/sample - loss: 1.0033 - accuracy: 0.6889\n",
      "Epoch 13/20\n",
      "1649/1649 [==============================] - 12s 7ms/sample - loss: 0.9744 - accuracy: 0.7035\n",
      "Epoch 14/20\n",
      "1649/1649 [==============================] - 12s 7ms/sample - loss: 0.9522 - accuracy: 0.7065\n",
      "Epoch 15/20\n",
      "1649/1649 [==============================] - 12s 7ms/sample - loss: 0.9556 - accuracy: 0.7041\n",
      "Epoch 16/20\n",
      "1649/1649 [==============================] - 12s 7ms/sample - loss: 0.9463 - accuracy: 0.6968\n",
      "Epoch 17/20\n",
      "1649/1649 [==============================] - 12s 7ms/sample - loss: 0.9321 - accuracy: 0.7083\n",
      "Epoch 18/20\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 0.9330 - accuracy: 0.6980\n",
      "Epoch 19/20\n",
      "1649/1649 [==============================] - 12s 7ms/sample - loss: 0.9008 - accuracy: 0.7162\n",
      "Epoch 20/20\n",
      "1649/1649 [==============================] - 12s 7ms/sample - loss: 0.9236 - accuracy: 0.7101\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23136fcfdc8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain, ytrain, batch_size=32, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(Xtest, ytest, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.8771  Accuaracy: 0.7312\n"
     ]
    }
   ],
   "source": [
    "print('Loss: {:.4f}  Accuaracy: {:.4}'.format(score[0],score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation functions are mathematical equations that determine the output of a neural network. The function is attached to each neuron in the network, and determines whether it should be activated (fired) or not, based on whether each neuron's input is relevant for the model's prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1\n",
    "#### Here the activation function is changed to tanh from relu as that was there in the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (5, 5), activation='tanh', kernel_initializer='glorot_uniform', bias_initializer='zeros'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(512, activation='tanh'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adadelta',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1649 samples\n",
      "Epoch 1/10\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 2.5208 - accuracy: 0.1516\n",
      "Epoch 2/10\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 2.2875 - accuracy: 0.2025\n",
      "Epoch 3/10\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 2.0926 - accuracy: 0.2638\n",
      "Epoch 4/10\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 1.9721 - accuracy: 0.3129\n",
      "Epoch 5/10\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 1.8484 - accuracy: 0.3511\n",
      "Epoch 6/10\n",
      "1649/1649 [==============================] - 11s 6ms/sample - loss: 1.7458 - accuracy: 0.4015\n",
      "Epoch 7/10\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 1.6551 - accuracy: 0.4336\n",
      "Epoch 8/10\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 1.5600 - accuracy: 0.4742\n",
      "Epoch 9/10\n",
      "1649/1649 [==============================] - 11s 6ms/sample - loss: 1.4902 - accuracy: 0.4961\n",
      "Epoch 10/10\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 1.4342 - accuracy: 0.5112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23138bdd1c8>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain, ytrain, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(Xtest, ytest, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.3063  Accuaracy: 0.6368\n"
     ]
    }
   ],
   "source": [
    "print('Loss: {:.4f}  Accuaracy: {:.4}'.format(score[0],score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The accuracy has decreased by a little bit and also the value of the loss funciton is more than the network palteau model of the base model. It has not reached the network plateau value as that of the base model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2\n",
    "#### Here the elu (Exponential Linear Unit) Activation function is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (5, 5), activation='elu', kernel_initializer='glorot_uniform', bias_initializer='zeros'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(512, activation='elu'),\n",
    "    tf.keras.layers.Dense(10, activation='elu')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adadelta',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1649 samples\n",
      "Epoch 1/10\n",
      "1649/1649 [==============================] - 11s 6ms/sample - loss: 6.8742 - accuracy: 0.0995s - loss: 6.8838 - accuracy: 0.09\n",
      "Epoch 2/10\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 6.3190 - accuracy: 0.1110\n",
      "Epoch 3/10\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 5.7866 - accuracy: 0.1079\n",
      "Epoch 4/10\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 5.3379 - accuracy: 0.1213\n",
      "Epoch 5/10\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 5.0915 - accuracy: 0.1243\n",
      "Epoch 6/10\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 4.5068 - accuracy: 0.1176\n",
      "Epoch 7/10\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 4.1948 - accuracy: 0.1413\n",
      "Epoch 8/10\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 3.8891 - accuracy: 0.1322\n",
      "Epoch 9/10\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 3.7367 - accuracy: 0.1528\n",
      "Epoch 10/10\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 3.5714 - accuracy: 0.1583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x231458b8788>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain, ytrain, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(Xtest, ytest, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.3718  Accuaracy: 0.1864\n"
     ]
    }
   ],
   "source": [
    "print('Loss: {:.4f}  Accuaracy: {:.4}'.format(score[0],score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAcNElEQVR4nO3dfZwdZX338c+XhBC4QZ6yoJDIIkQlKqCsAatgEOzNgyYoqSRKIbdoamuKVZGiRQz4gGKLbe9GJQKCCgSkggHRgEBAoWA2GpAQUkKAZInA8hAgUEkCv/4x18Lk5Ozu2c3O2STX9/16ndeembnmmmtmz5nvzDXnzFFEYGZm+dpisBtgZmaDy0FgZpY5B4GZWeYcBGZmmXMQmJllzkFgZpY5B4GZWeYcBGaJpIWSxlVQ7+slrZI0pIK63y3p/lT/MQNdf2k5qyS9oar6B4Kk6ZJ+Mtjt2BQ5CAaRpLmSnpa01WC3pQqS7pP08TrjPyOpvTQ8TNITkraV9BZJ16ftslLSfElH9bKccZJC0ql9aNtFkr5WHhcRb4mIuY3W0UPdD0k6vFTvsojYNiJe2tC66zgL+I9U/9UV1A9Aqn8p1N92tmlzEAwSSa3AwUAA45u87KFNWtTFwAl1xv91mtblEGBBRKwCrgFuAHYFdgFOBp7tZTknAk+lv7nZA1g42I2wTVxE+DEID+AM4DbgXODammlbA/8CPAw8A/wW2DpNew9wO7ASWA5MSePnAp8o1TEF+G1pOIBPA/cDD6Zx/5bqeBaYDxxcKj8E+BLwAPBcmj4K+D7wzzXt/TnwuTrrOBJYC+xRGrcPsBoYURp3LvA5YERq5w592I7bpPZNSvW21Uxfb3sBU4E1qfwq4JpU9iHgcGA34H+AnUr1vB14AtgS2Au4CXgyjbukq83Aj4GX0/yrgFOB1rReQ1OZ3YDZFOG1BPhkaTnTgSuAH6X1Wli7TqWyD9Qsa6uudaip7yfpeVc7TgSWpbb/U2//89LrZ+8ett0+FK/BlanN40v1XgTMAH6R6r0T2KubdfoVMK1m3F3Ahxt4zZbXdRzQUVPPK9uG4iD4tLSuT6ZtvlOaNhz4SRq/EpgH7DrY+4wqH4PegFwfaQfwd8AB6Y21a2najPSm2j29Of8ivclfn95Ikyl2SDsD+6d55tJ7ENwA7MSroXJ8qmMo8HngUWB4mvYF4I/AmwAB+6Wyh6Q3olK5HSl2RLt1s543AKeXhs8Grq4pc19pOfcD1wLHNPLmozi7+FPaTtcA/16a1tP2ugj4Wk1d5R3FTay7g/428P30fG/g/el/0gLcCvxrvXrScCvrBsEtwHfTDmd/oBM4LE2bDvwZOCqt09nAHT2sf+2yaoens34Q/IDiYGM/4EVgn57+56XXz971tl3atksoQmQY8L603d9UKv8UMJbitXYJMKub9TkBuK00PIZiZ7xVA6/Z8rqOo+cg+AfgDoqDla2A84DL0rS/oXgtbZP+BwcArxnsfUaVj0FvQI4PiqPUNaSjYood4WfT8y0odqz71Znvi8BV3dQ5l96D4H29tOvpruUCi4EJdcqI4mjykDT8SeCmHuo8HlhcWrdlwIdK098APFAaHgn8B68e7d4KjO6h/l+TdsIUO/xOYMsGttc6O7M0rryj+ETXeqV1Xt61znXqOgb4Q7160nBr2v5DKc6qXgK2K00/G7goPZ8O/Lo0bQzwPz2sf+2yaoens34QjCxN/x0wqaf/een1010QHEyxQ96iNO4yYHqp/PmlaUcB93WznO2A50lnkcDXgQsbfM2W13UcPQfBIlL4puHXUbwnhwIfpziL3LeR9/Pm8PA1gsFxInB9RDyRhi/l1f7tERRHig/UmW9UN+Mbtbw8IOnzkhZJekbSSmD7tPxulxXFu2YWxU4X4KMUR3jd+RnwOkkHUbw5t6HoIuhyNHBdqf6OiJgWEXtR9H8/T9FNsh5Jo4BDS8v/OcW2O7qndWjQlcC7JO1GcRYUwG/ScneRNEvSI5KepehGGNF9VevYDXgqIp4rjXuY4uyvy6Ol5y8Awwf4uk5t/dum5/3dXrsByyPi5dK43tZpW+pI2+UXFF19pL+vvL56ec32xR7AVekDCSspguElimtTPwbmALMkrZB0jqQt+7GMTYaDoMkkbQ18BHivpEclPQp8FthP0n4U/bZ/puiHrrW8m/FQ7DC3KQ2/tk6ZKLXjYOAfU1t2jIgdKK5HqIFlXQZMlLQHcCDwn92UIyJeoNipnkDRjTMrIlaXihzFusFQnnc5RTfZW7up/q8pXsPXpO24lCIIui5Q97QO0c34rmWvBK6n2D4fpeg26Jrn7DT/vhHxGoqzHpVn76HqFcBOkrYrjXs98EhP7emDRl4H3elpe5XVrt8KYJSk8v5kQ9bpMmCypHdRdGHdDA29ZsvW2Q7po7stpenLgSMjYofSY3hEPBIRayLizIgYQ9Et+wHqf+hhs+EgaL5jKI48xlD0D+9PcaHtN8AJ6ajqQuBcSbtJGiLpXekjppcAh0v6iKShknaWtH+qdwHwYUnbSNobOKmXdmxHcSG3Exgq6QzgNaXp5wNflTRahX0l7QwQEX9I850PzEk7zZ5cDBwHHEvp00IpFMdSdGshaUdJZ0raW9IWkkZQnKbf0U29JwBn8up23D8t4+jU1p6212MU3VI9uTQt49j0vMt2FBdKV0ranaJvvazbulO43Q6cLWm4pH0p/lc9nVX1xQJgkqQtJbUBE/swb7f/8xq163cnxY731LTcccAHKc4c++M6iiP2s4DLS2cavb1my/6b4kzq6HQ0fzrFtYAu3we+ng5mkNQiaUJ6fqikt6XweJaiy6iKj/5uNBwEzXci8MMoPlv+aNeDol/8Y6kL4BSKi3bzKC6yfYui/3UZxRH059P4BRQX9AC+Q/FJjscodra97VjmAL+keMM8THEWUu46OpfikxTXU7wZLqA4OutyGcUnbMo7yO7cSnHk9khEzCuNPwz4r4j4cxpeTdGP/eu0zHsoLmZOqa0wdTW1AjPK2zEiZlNcuJzcy/a6ABiTuga6+/z9bGA08FhE3FUafybwjrROv6Do/io7Gzg91X1KnXonp7avAK4CvhIRN3TThr76MsVR/dOpnY38f7r09j/vss62S2d444EjKc5ov0txUHNff1YgIl6k2Ka1r6/eXrPlOp6h+DDG+RRnJs8DHaUi/0bx/71e0nMUBxsHpmmvpTiLfZaiy+gWiu6/zVbXJz/Mmk7Sd4F7IuK7g90Ws5w164tFZvUsoPiYnpkNIp8RmJllztcIzMwyt8l1DY0YMSJaW1sHuxlmZpuU+fPnPxERLfWmbXJB0NraSnt7e+8FzczsFZIe7m6au4bMzDLnIDAzy5yDwMwscw4CM7PMOQjMzDLnIDAzy5yDwMwscw4CM7PMOQjMzDK3yX2zeIOo3g8ZmSW+AaNlymcEZmaZcxCYmWXOQWBmljkHgZlZ5hwEZmaZcxCYmWXOQWBmljkHgZlZ5ioNAklHSFosaYmk07op8xFJ90paKOnSKttjZmbrq+ybxZKGADOA9wMdwDxJsyPi3lKZ0cAXgXdHxNOSdqmqPWZmVl+VZwRjgSURsTQiVgOzgAk1ZT4JzIiIpwEi4vEK22NmZnVUGQS7A8tLwx1pXNkbgTdKuk3SHZKOqFeRpKmS2iW1d3Z2VtRcM7M8VRkE9e7wVntXr6HAaGAcMBk4X9IO680UMTMi2iKiraWlZcAbamaWsyqDoAMYVRoeCayoU+bnEbEmIh4EFlMEg5mZNUmVQTAPGC1pT0nDgEnA7JoyVwOHAkgaQdFVtLTCNpmZWY3KgiAi1gLTgDnAIuCKiFgo6SxJ41OxOcCTku4Fbga+EBFPVtUmMzNbn2IT+zGOtra2aG9v79/M/mEa68km9l4w6wtJ8yOird40f7PYzCxzDgIzs8w5CMzMMucgMDPLnIPAzCxzDgIzs8w5CMzMMucgMDPLnIPAzCxzDgIzs8w5CMzMMucgMDPLnIPAzCxzDgIzs8w5CMzMMucgMDPLnIPAzCxzDgIzs8w5CMzMMucgMDPLnIPAzCxzDgIzs8w5CMzMMldpEEg6QtJiSUsknVZn+hRJnZIWpMcnqmyPmZmtb2hVFUsaAswA3g90APMkzY6Ie2uKXh4R06pqh5mZ9azKM4KxwJKIWBoRq4FZwIQKl2dmZv1QZRDsDiwvDXekcbWOlXS3pCsljapXkaSpktoltXd2dlbRVjOzbFUZBKozLmqGrwFaI2Jf4NfAxfUqioiZEdEWEW0tLS0D3Ewzs7xVGQQdQPkIfySwolwgIp6MiBfT4A+AAypsj5mZ1VFlEMwDRkvaU9IwYBIwu1xA0utKg+OBRRW2x8zM6qjsU0MRsVbSNGAOMAS4MCIWSjoLaI+I2cDJksYDa4GngClVtcfMzOpTRG23/catra0t2tvb+zez6l22MEs2sfeCWV9Imh8RbfWm+ZvFZmaZcxCYmWXOQWBmljkHgZlZ5hwEZmaZcxCYmWXOQWBmljkHgZlZ5hwEZmaZcxCYmWXOQWBmljkHgZlZ5hwEZmaZcxCYmWXOQWBmljkHgZlZ5hwEZmaZcxCYmWXOQWBmljkHgZlZ5hwEZmaZcxCYmWXOQWBmljkHgZlZ5ioNAklHSFosaYmk03ooN1FSSGqrsj1mZra+yoJA0hBgBnAkMAaYLGlMnXLbAScDd1bVFjMz616VZwRjgSURsTQiVgOzgAl1yn0VOAf4c4VtMTOzblQZBLsDy0vDHWncKyS9HRgVEdf2VJGkqZLaJbV3dnYOfEvNzDLWaxBImiZpx37UrTrjolTvFsB3gM/3VlFEzIyItohoa2lp6UdTzMysO42cEbwWmCfpinTxt94Ovp4OYFRpeCSwojS8HfBWYK6kh4CDgNm+YGxm1ly9BkFEnA6MBi4ApgD3S/qGpL16mXUeMFrSnpKGAZOA2aV6n4mIERHRGhGtwB3A+Iho79+qmJlZfzR0jSAiAng0PdYCOwJXSjqnh3nWAtOAOcAi4IqIWCjpLEnjN7jlZmY2IFTs43soIJ0MnAg8AZwPXB0Ra1If//0R0duZwYBqa2uL9vZ+njQ03KtlWerlvWC2KZM0PyLqdr0PbWD+EcCHI+Lh8siIeFnSBwaigWZmNnga6Rq6Dniqa0DSdpIOBIiIRVU1zMzMmqORIPgesKo0/HwaZ2Zmm4FGgkBRupAQES/TWJeSmZltAhoJgqWSTpa0ZXp8BlhadcPMzKw5GgmCTwF/ATxC8SWxA4GpVTbKzMyap9cunoh4nOLLYGZmthnqNQgkDQdOAt4CDO8aHxEfr7BdZmbWJI10Df2Y4n5D/xe4heKeQc9V2SgzM2ueRoJg74j4MvB8RFwMHA28rdpmmZlZszQSBGvS35WS3gpsD7RW1iIzM2uqRr4PMDP9HsHpFHcP3Rb4cqWtMjOzpukxCNKN5Z6NiKeBW4E3NKVVZmbWND12DaVvEU9rUlvMzGwQNHKN4AZJp0gaJWmnrkflLTMzs6Zo5BpB1/cFPl0aF7ibyMxss9DIN4v3bEZDzMxscDTyzeIT6o2PiB8NfHPMzKzZGukaemfp+XDgMOD3gIPAzGwz0EjX0N+XhyVtT3HbCTMz2ww08qmhWi8Aowe6IWZmNjgauUZwDcWnhKAIjjHAFVU2yszMmqeRawT/XHq+Fng4Ijoqao+ZmTVZI11Dy4A7I+KWiLgNeFJSayOVSzpC0mJJSySdVmf6pyT9UdICSb+VNKZPrTczsw3WSBD8FHi5NPxSGtcjSUOAGcCRFN1Jk+vs6C+NiLdFxP7AOcC5DbXazMwGTCNBMDQiVncNpOfDGphvLLAkIpameWYBE8oFIuLZ0uD/4dVrEWZm1iSNBEGnpPFdA5ImAE80MN/uwPLScEcatw5Jn5b0AMUZwcn1KpI0VVK7pPbOzs4GFm1mZo1qJAg+BXxJ0jJJy4B/BP6mgflUZ9x6R/wRMSMi9kr1nl6vooiYGRFtEdHW0tLSwKLNzKxRjXyh7AHgIEnbAoqIRn+vuAMYVRoeCazoofws4HsN1m1mZgOk1zMCSd+QtENErIqI5yTtKOlrDdQ9DxgtaU9Jw4BJFL9wVq67/MW0o4H7+9J4MzPbcI10DR0ZESu7BtKvlR3V20wRsZbiR23mAIuAKyJioaSzStccpklaKGkB8DngxD6vgZmZbZBGvlA2RNJWEfEigKStga0aqTwirgOuqxl3Run5Z/rQVjMzq0AjQfAT4EZJP0zD/w+4uLommZlZMzVysfgcSXcDh1N8EuhXwB5VN8zMzJqj0buPPkrx7eJjKX6PYFFlLTIzs6bq9oxA0hspPukzGXgSuJzi46OHNqltZmbWBD11Dd0H/Ab4YEQsAZD02aa0yszMmqanrqFjKbqEbpb0A0mHUf/bwmZmtgnrNggi4qqIOA54MzAX+Cywq6TvSfrLJrXPzMwq1uvF4oh4PiIuiYgPUNwmYgGw3m8LmJnZpqlPv1kcEU9FxHkR8b6qGmRmZs3Vnx+vNzOzzYiDwMwscw4CM7PMOQjMzDLnIDAzy5yDwMwscw4CM7PMOQjMzDLnIDAzy5yDwMwscw4CM7PMOQjMzDLnIDAzy5yDwMwscw4CM7PMVRoEko6QtFjSEknr/ZiNpM9JulfS3ZJulLRHle0xM7P1VRYEkoYAM4AjgTHAZEljaor9AWiLiH2BK4FzqmqPmZnVV+UZwVhgSUQsjYjVwCxgQrlARNwcES+kwTsofgrTzMyaqMog2B1YXhruSOO6cxLwy3oTJE2V1C6pvbOzcwCbaGZmVQaB6oyLugWl44E24Nv1pkfEzIhoi4i2lpaWAWyimZkNrbDuDmBUaXgksKK2kKTDgX8C3hsRL1bYHjMzq6PKM4J5wGhJe0oaBkwCZpcLSHo7cB4wPiIer7AtZmbWjcrOCCJiraRpwBxgCHBhRCyUdBbQHhGzKbqCtgV+KglgWUSMr6pNZhs7nVmvR9WsEF+p27u+warsGiIirgOuqxl3Run54VUu38zMeudvFpuZZc5BYGaWOQeBmVnmHARmZplzEJiZZc5BYGaWOQeBmVnmHARmZplzEJiZZc5BYGaWOQeBmVnmHARmZplzEJiZZc5BYGaWOQeBmVnmHARmZplzEJiZZc5BYGaWOQeBmVnmHARmZplzEJiZZc5BYGaWOQeBmVnmKg0CSUdIWixpiaTT6kw/RNLvJa2VNLHKtpiZWX2VBYGkIcAM4EhgDDBZ0piaYsuAKcClVbXDzMx6NrTCuscCSyJiKYCkWcAE4N6uAhHxUJr2coXtMDOzHlTZNbQ7sLw03JHG9ZmkqZLaJbV3dnYOSOPMzKxQZRCozrjoT0URMTMi2iKiraWlZQObZWZmZVUGQQcwqjQ8ElhR4fLMzKwfqgyCecBoSXtKGgZMAmZXuDwzM+uHyoIgItYC04A5wCLgiohYKOksSeMBJL1TUgfwV8B5khZW1R4zM6uvyk8NERHXAdfVjDuj9HweRZeRmZkNEn+z2Mwscw4CM7PMOQjMzDLnIDAzy5yDwMwscw4CM7PMOQjMzDLnIDAzy5yDwMwscw4CM7PMOQjMzDLnIDAzy5yDwMwscw4CM7PMOQjMzDLnIDAzy5yDwMwscw4CM7PMOQjMzDLnIDAzy5yDwMwscw4CM7PMOQjMzDLnIDAzy1ylQSDpCEmLJS2RdFqd6VtJujxNv1NSa5XtMTOz9VUWBJKGADOAI4ExwGRJY2qKnQQ8HRF7A98BvlVVe8zMrL4qzwjGAksiYmlErAZmARNqykwALk7PrwQOk6QK22RmZjWGVlj37sDy0nAHcGB3ZSJiraRngJ2BJ8qFJE0FpqbBVZIWV9Li/IygZltnzccgGyO/Rks0fYNeo3t0N6HKIKjX4uhHGSJiJjBzIBplr5LUHhFtg90Os+74NdocVXYNdQCjSsMjgRXdlZE0FNgeeKrCNpmZWY0qg2AeMFrSnpKGAZOA2TVlZgMnpucTgZsiYr0zAjMzq05lXUOpz38aMAcYAlwYEQslnQW0R8Rs4ALgx5KWUJwJTKqqPVaXu9tsY+fXaBPIB+BmZnnzN4vNzDLnIDAzy5yDYDMjaQdJf7cB88+V5I/r2aCT9JCkEYPdjhw4CDY/OwD9DgIzy4+DYPPzTWAvSQskfUfSjZJ+L+mPkiYASGqVtEjSDyQtlHS9pK1LdfyVpN9J+m9JBw/OalhOJB2fXnMLJJ2X7lXWNa1V0j2l4VMkTR+Uhm6mHASbn9OAByJif+ALwIci4h3AocC/lO7lNBqYERFvAVYCx5bqGBoRY4F/AL7SvKZbjiTtAxwHvDu9bl8CPja4rcpLlbeYsMEn4BuSDgFepri3065p2oMRsSA9nw+0lub7WTfjzapwGHAAMC8dp2wNPD6oLcqMg2Dz9jGgBTggItZIeggYnqa9WCr3EsWbj5ppL+HXiFVPwMUR8cV1RkpT0tO1rNt7MRwbUO4a2vw8B2yXnm8PPJ5C4FB6uPug2SC6EZgoaRcASTtJKr9WHwN2kbSzpK2ADwxGIzdnPtrbzETEk5JuSxfX5gFvltQOLADuG9zWma0vIu6VdDpwvaQtgDXAp0vT16Rb09wJPIhfxwPOt5gwM8ucu4bMzDLnIDAzy5yDwMwscw4CM7PMOQjMzDLnILCNjqQPSQpJb26g7BRJu5WGz5c0pp/L/VLN8O39qadOvRdJejDdR2eBpJMHot5S/QO2DSxP/viobXQkXQG8DrgxIqb3UnYucEpEtA/AcldFxLYbWk+dei8Cro2IKwe67lT/XAZoG1iefEZgGxVJ2wLvBk6i5jesJZ2a7qJ6l6RvSpoItAGXpCPtrbt+T0HS30o6pzTvFEn/Pz2/WtL8dOfVqWncN4GtUz2XpHGr0l9J+rake9Lyj0vjx6XlXSnpPkmXlG7q18i6rio9n5gCo+sM4t8l3S5paVrPPm+DVH5yKn+PpG+Vly3p66meOyTtiuUrIvzwY6N5AMcDF6TntwPvSM+PTMPbpOGd0t+5QFtp/rkUO8YWYElp/C+B99TMuzVwD7BzGl5V05ZV6e+xwA3AEIqb9i2jOGMZBzwDjKQ4qPqvrmXU1HMRxTdiF6TH22qXB0wELiqV/2mqc0zXevRjG+yW2tpCcReBm4BjUpkAPpienwOcPtj/ez8G7+EzAtvYTAZmpeez0jDA4cAPI+IFgIh4qqdKIqITWCrpIEk7A28CbkuTT5Z0F3AHMIriltw9eQ9wWUS8FBGPAbcA70zTfhcRHRHxMsVOvrWbOr4QEfunxx97WR7A1RHxckTcy6t3jO3TNkhtnBsRnRGxFrgEOCRNWw1cm577LrOZ872GbKORdtjvA94qKSiOwEPSqRR3qOzrBa3LgY9Q3JvmqogISeModqjviogXUv96b3ez7Km7p/Yurn15T5XXp7YN5XpV+tuXbdBTu9dERFddvsts5nxGYBuTicCPImKPiGiNiFEUXSrvAa4HPi5pGyjuUJnmKd9ttdbPgGMoziouT+O2B55OIfBm4KBS+TWStqxTz63AcZKGSGqhOKr+Xb/X8lWPSdon3WjtQw2U7+s2uBN4r6QRKn7xazLF2YzZOhwEtjGZDFxVM+4/gY9GxK+A2UC7pAXAKWn6RcD3uy6UlmeMiKeBe4E9IqJrx/0rYKiku4GvUnQPdZkJ3N11sbjkKuBu4C6KfvZTI+LR/q/mK06j6J65CfhTb4X7ug0i4k/AF4GbU9t/HxE/H4B222bGHx81M8uczwjMzDLnIDAzy5yDwMwscw4CM7PMOQjMzDLnIDAzy5yDwMwsc/8L+jTmIbk2pioAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = ['tanh','elu'] \n",
    "# corresponding y axis values \n",
    "y = [0.6368,0.1864]  \n",
    "# plotting the points  \n",
    "plt.bar(x,y,width = 0.8, color = ['red', 'green']) \n",
    "# naming the x axis \n",
    "plt.xlabel('Activation Function') \n",
    "# naming the y axis \n",
    "plt.ylabel('Accuracy') \n",
    "  \n",
    "plt.title('Accuracv V/S Activation funciton values') \n",
    "  \n",
    "# function to show the plot \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The accuracy has decreased drastically and also the value of the loss funciton is more than the network palteau model of the base model. It has not reached the network plateau value as that of the base model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function is a function that measures the performance of a Machine Learning model for given data. Cost Function quantifies the error between predicted values and expected values and presents it in the form of a single real number. It is also called cost, loss or error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1\n",
    "#### The model 1 with the loss( cost) of binary_cross_entorpy is used here instead of the categorical cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (5, 5), activation='relu', kernel_initializer='glorot_uniform', bias_initializer='zeros'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer='adadelta',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1649 samples\n",
      "Epoch 1/10\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 0.3600 - accuracy: 0.8976\n",
      "Epoch 2/10\n",
      "1649/1649 [==============================] - 11s 6ms/sample - loss: 0.3445 - accuracy: 0.8984\n",
      "Epoch 3/10\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 0.3318 - accuracy: 0.8988\n",
      "Epoch 4/10\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 0.3260 - accuracy: 0.8988\n",
      "Epoch 5/10\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 0.3167 - accuracy: 0.8998\n",
      "Epoch 6/10\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 0.3060 - accuracy: 0.9001\n",
      "Epoch 7/10\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 0.2998 - accuracy: 0.9001\n",
      "Epoch 8/10\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 0.2935 - accuracy: 0.9016\n",
      "Epoch 9/10\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 0.2882 - accuracy: 0.9011\n",
      "Epoch 10/10\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 0.2782 - accuracy: 0.9029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2315fde6dc8>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain, ytrain, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(Xtest, ytest, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2825  Accuaracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "print('Loss: {:.4f}  Accuaracy: {:.4}'.format(score[0],score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There is a drastic improvement in the accuracy compared to the base model and the model is better than the network plateaued model as the base model having both ahiger accuracy and also a very low loss rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2\n",
    "#### Here the hinge loss (cost) function is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (5, 5), activation='relu', kernel_initializer='glorot_uniform', bias_initializer='zeros'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='hinge',\n",
    "             optimizer='adadelta',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1649 samples\n",
      "Epoch 1/10\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 1.0811 - accuracy: 0.0879\n",
      "Epoch 2/10\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 1.0807 - accuracy: 0.0928\n",
      "Epoch 3/10\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 1.0804 - accuracy: 0.0958s -\n",
      "Epoch 4/10\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 1.0793 - accuracy: 0.1104\n",
      "Epoch 5/10\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 1.0793 - accuracy: 0.1037\n",
      "Epoch 6/10\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 1.0788 - accuracy: 0.1037\n",
      "Epoch 7/10\n",
      "1649/1649 [==============================] - 11s 6ms/sample - loss: 1.0781 - accuracy: 0.1328\n",
      "Epoch 8/10\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 1.0778 - accuracy: 0.1231\n",
      "Epoch 9/10\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 1.0772 - accuracy: 0.1389\n",
      "Epoch 10/10\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 1.0767 - accuracy: 0.1486\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x231641532c8>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain, ytrain, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(Xtest, ytest, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.0778  Accuaracy: 0.2131\n"
     ]
    }
   ],
   "source": [
    "print('Loss: {:.4f}  Accuaracy: {:.4}'.format(score[0],score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here there is severe dip in the accuracy of the model and also the in regards to the network plateau model the base model is more accurate and has less loss compared to this model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An epoch is a hyperparameter that is specified before training the deep learning model\n",
    "#### An epoch refers to one cycle through the full training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1\n",
    "#### Here 5 epochs are used with all the other parameters being the same as the base model\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (5, 5), activation='relu', kernel_initializer='glorot_uniform', bias_initializer='zeros'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adadelta',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1649 samples\n",
      "Epoch 1/5\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 2.5269 - accuracy: 0.1122\n",
      "Epoch 2/5\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 2.3988 - accuracy: 0.1298\n",
      "Epoch 3/5\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 2.2983 - accuracy: 0.1753\n",
      "Epoch 4/5\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 2.2376 - accuracy: 0.1977\n",
      "Epoch 5/5\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 2.1593 - accuracy: 0.2220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2316ccdb048>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain, ytrain, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(Xtest, ytest, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.2360  Accuaracy: 0.3099\n"
     ]
    }
   ],
   "source": [
    "print('Loss: {:.4f}  Accuaracy: {:.4}'.format(score[0],score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy is low as compared to the absed model and the also with regards the network plateau the base model has less error and better accuracy than the current model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2\n",
    "#### epoch value is set to 25 with all the paraemters same as the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (5, 5), activation='relu', kernel_initializer='glorot_uniform', bias_initializer='zeros'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adadelta',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1649 samples\n",
      "Epoch 1/25\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 0.9007 - accuracy: 0.7119\n",
      "Epoch 2/25\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 0.8809 - accuracy: 0.7216\n",
      "Epoch 3/25\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 0.8621 - accuracy: 0.7350\n",
      "Epoch 4/25\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 0.8709 - accuracy: 0.7241\n",
      "Epoch 5/25\n",
      "1649/1649 [==============================] - 13s 8ms/sample - loss: 0.8562 - accuracy: 0.7247\n",
      "Epoch 6/25\n",
      "1649/1649 [==============================] - 12s 7ms/sample - loss: 0.8317 - accuracy: 0.7368\n",
      "Epoch 7/25\n",
      "1649/1649 [==============================] - 13s 8ms/sample - loss: 0.8312 - accuracy: 0.7380\n",
      "Epoch 8/25\n",
      "1649/1649 [==============================] - 12s 7ms/sample - loss: 0.8207 - accuracy: 0.7447\n",
      "Epoch 9/25\n",
      "1649/1649 [==============================] - 12s 7ms/sample - loss: 0.8109 - accuracy: 0.7350\n",
      "Epoch 10/25\n",
      "1649/1649 [==============================] - 12s 7ms/sample - loss: 0.7925 - accuracy: 0.7526\n",
      "Epoch 11/25\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 0.7701 - accuracy: 0.7623\n",
      "Epoch 12/25\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 0.7874 - accuracy: 0.7617\n",
      "Epoch 13/25\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 0.7828 - accuracy: 0.7520\n",
      "Epoch 14/25\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 0.7605 - accuracy: 0.7629\n",
      "Epoch 15/25\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 0.7609 - accuracy: 0.7532\n",
      "Epoch 16/25\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 0.7366 - accuracy: 0.7617\n",
      "Epoch 17/25\n",
      "1649/1649 [==============================] - 11s 6ms/sample - loss: 0.7197 - accuracy: 0.7774\n",
      "Epoch 18/25\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 0.7228 - accuracy: 0.7702\n",
      "Epoch 19/25\n",
      "1649/1649 [==============================] - 11s 6ms/sample - loss: 0.7181 - accuracy: 0.7732\n",
      "Epoch 20/25\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 0.7227 - accuracy: 0.7708\n",
      "Epoch 21/25\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 0.7052 - accuracy: 0.7762\n",
      "Epoch 22/25\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 0.6981 - accuracy: 0.7823\n",
      "Epoch 23/25\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 0.6787 - accuracy: 0.8017\n",
      "Epoch 24/25\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 0.6984 - accuracy: 0.7817\n",
      "Epoch 25/25\n",
      "1649/1649 [==============================] - 12s 7ms/sample - loss: 0.6802 - accuracy: 0.7950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x231386d6f88>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain, ytrain, batch_size=32, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(Xtest, ytest, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7438  Accuaracy: 0.7651\n"
     ]
    }
   ],
   "source": [
    "print('Loss: {:.4f}  Accuaracy: {:.4}'.format(score[0],score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [5,25] \n",
    "# corresponding y axis values \n",
    "y = [0.3099,0.7631]  \n",
    "# plotting the points  \n",
    "plt.bar(x,y,width = 0.8, color = ['red', 'blue']) \n",
    "# naming the x axis \n",
    "plt.xlabel('Epochs') \n",
    "# naming the y axis \n",
    "plt.ylabel('Accuracy') \n",
    "  \n",
    "plt.title('Accuracv V/S Epoch values') \n",
    "  \n",
    "# function to show the plot \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The accuracy and the loss are almost same as the base model and is as accurate as the base model having the network plateaus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Estimators mainly involve optimizers that shape and mold the model into its most accurate possible form by futzing with the weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1\n",
    "#### Here the adam optimizer is used which is chaged from the one used in the base model of adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (5, 5), activation='relu', kernel_initializer='glorot_uniform', bias_initializer='zeros'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1649 samples\n",
      "Epoch 1/10\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 2.1614 - accuracy: 0.4948\n",
      "Epoch 2/10\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 0.5642 - accuracy: 0.8199\n",
      "Epoch 3/10\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 0.2741 - accuracy: 0.9133s -\n",
      "Epoch 4/10\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 0.1699 - accuracy: 0.9460\n",
      "Epoch 5/10\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 0.0964 - accuracy: 0.9673\n",
      "Epoch 6/10\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 0.0471 - accuracy: 0.9873s - loss: 0.0440 - accura\n",
      "Epoch 7/10\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 0.0363 - accuracy: 0.9897\n",
      "Epoch 8/10\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 0.0252 - accuracy: 0.9927\n",
      "Epoch 9/10\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 0.0284 - accuracy: 0.9909\n",
      "Epoch 10/10\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 0.0285 - accuracy: 0.9921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2317624bfc8>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain, ytrain, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(Xtest, ytest, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5306  Accuaracy: 0.8232\n"
     ]
    }
   ],
   "source": [
    "print('Loss: {:.4f}  Accuaracy: {:.4}'.format(score[0],score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The accuracy has increased with respect to the base model and the loss has decreased and is more accurate than the base model with the network plateaus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2\n",
    "#### The adagrad optimizer is used in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (5, 5), activation='relu', kernel_initializer='glorot_uniform', bias_initializer='zeros'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adagrad',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1649 samples\n",
      "Epoch 1/10\n",
      "1649/1649 [==============================] - 12s 7ms/sample - loss: 1.7555 - accuracy: 0.5421\n",
      "Epoch 2/10\n",
      "1649/1649 [==============================] - 12s 7ms/sample - loss: 0.4867 - accuracy: 0.8490\n",
      "Epoch 3/10\n",
      "1649/1649 [==============================] - 12s 7ms/sample - loss: 0.2786 - accuracy: 0.9193\n",
      "Epoch 4/10\n",
      "1649/1649 [==============================] - 14s 9ms/sample - loss: 0.1652 - accuracy: 0.9654\n",
      "Epoch 5/10\n",
      "1649/1649 [==============================] - 15s 9ms/sample - loss: 0.1154 - accuracy: 0.9782\n",
      "Epoch 6/10\n",
      "1649/1649 [==============================] - 12s 8ms/sample - loss: 0.0701 - accuracy: 0.9921\n",
      "Epoch 7/10\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 0.0499 - accuracy: 0.9939\n",
      "Epoch 8/10\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 0.0350 - accuracy: 0.9982\n",
      "Epoch 9/10\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 0.0257 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1649/1649 [==============================] - 12s 7ms/sample - loss: 0.0221 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23176cdc888>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain, ytrain, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(Xtest, ytest, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5232  Accuaracy: 0.8571\n"
     ]
    }
   ],
   "source": [
    "print('Loss: {:.4f}  Accuaracy: {:.4}'.format(score[0],score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The accuracy has increased with respect to the base model and the loss has decreased and is more accurate than the base model with the network plateaus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Learning refers to a neural network architecture with a relatively large number of layers, in which the first several layers mostly extract significant features from the data, and the last layers are mostly engaged in correlating the extracted features to outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1 \n",
    "#### This has an extra layer with the same kernel size and features as the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (5, 5), activation='relu', kernel_initializer='glorot_uniform', bias_initializer='zeros'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(32, (5, 5), activation='relu', kernel_initializer='glorot_uniform', bias_initializer='zeros'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adagrad',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1649 samples\n",
      "Epoch 1/10\n",
      "1649/1649 [==============================] - 12s 7ms/sample - loss: 1.7840 - accuracy: 0.5434\n",
      "Epoch 2/10\n",
      "1649/1649 [==============================] - 11s 6ms/sample - loss: 0.6496 - accuracy: 0.7853\n",
      "Epoch 3/10\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 0.4618 - accuracy: 0.8405\n",
      "Epoch 4/10\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 0.3691 - accuracy: 0.8811\n",
      "Epoch 5/10\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 0.3020 - accuracy: 0.9030\n",
      "Epoch 6/10\n",
      "1649/1649 [==============================] - 11s 6ms/sample - loss: 0.2373 - accuracy: 0.9357\n",
      "Epoch 7/10\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 0.2144 - accuracy: 0.9327\n",
      "Epoch 8/10\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 0.1873 - accuracy: 0.9454\n",
      "Epoch 9/10\n",
      "1649/1649 [==============================] - 11s 6ms/sample - loss: 0.1693 - accuracy: 0.9509\n",
      "Epoch 10/10\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 0.1409 - accuracy: 0.9594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2317e54ba48>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain, ytrain, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(Xtest, ytest, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5058  Accuaracy: 0.8547\n"
     ]
    }
   ],
   "source": [
    "print('Loss: {:.4f}  Accuaracy: {:.4}'.format(score[0],score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The accuracy has increased with respect to the base model and the loss has decreased and is more accurate than the base model with the network plateaus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2\n",
    "#### Here an extra layer is added and the number of layers and the size both are varied compared to the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (5, 5), activation='relu', kernel_initializer='glorot_uniform', bias_initializer='zeros'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(32, (5, 5), activation='relu', kernel_initializer='glorot_uniform', bias_initializer='zeros'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (5, 5), activation='relu', kernel_initializer='glorot_uniform', bias_initializer='zeros'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adagrad',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1649 samples\n",
      "Epoch 1/10\n",
      "1649/1649 [==============================] - 13s 8ms/sample - loss: 1.7418 - accuracy: 0.4857\n",
      "Epoch 2/10\n",
      "1649/1649 [==============================] - 13s 8ms/sample - loss: 0.8370 - accuracy: 0.7198\n",
      "Epoch 3/10\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 0.6285 - accuracy: 0.7908\n",
      "Epoch 4/10\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 0.5204 - accuracy: 0.8326\n",
      "Epoch 5/10\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 0.4316 - accuracy: 0.8617\n",
      "Epoch 6/10\n",
      "1649/1649 [==============================] - 10s 6ms/sample - loss: 0.3854 - accuracy: 0.8805\n",
      "Epoch 7/10\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 0.3691 - accuracy: 0.8696\n",
      "Epoch 8/10\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 0.3230 - accuracy: 0.8914\n",
      "Epoch 9/10\n",
      "1649/1649 [==============================] - 11s 6ms/sample - loss: 0.2894 - accuracy: 0.9090\n",
      "Epoch 10/10\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 0.2787 - accuracy: 0.9078\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x231aa592e88>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain, ytrain, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(Xtest, ytest, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6293  Accuaracy: 0.8136\n"
     ]
    }
   ],
   "source": [
    "print('Loss: {:.4f}  Accuaracy: {:.4}'.format(score[0],score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The accuracy has increased with respect to the base model and the loss has decreased and is more accurate than the base model with the network plateaus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Network Initialization is also known as the kernel intialization wherein we intitalize small numbers to the neural netwrok model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1 having unfiorm intializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (5, 5), activation='relu', kernel_initializer='uniform', bias_initializer='zeros'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adagrad',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1649 samples\n",
      "Epoch 1/10\n",
      "1649/1649 [==============================] - 13s 8ms/sample - loss: 1.3665 - accuracy: 0.5785\n",
      "Epoch 2/10\n",
      "1649/1649 [==============================] - 13s 8ms/sample - loss: 0.4190 - accuracy: 0.8684\n",
      "Epoch 3/10\n",
      "1649/1649 [==============================] - 12s 7ms/sample - loss: 0.2383 - accuracy: 0.9351\n",
      "Epoch 4/10\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 0.1463 - accuracy: 0.9654\n",
      "Epoch 5/10\n",
      "1649/1649 [==============================] - 12s 7ms/sample - loss: 0.0944 - accuracy: 0.9818\n",
      "Epoch 6/10\n",
      "1649/1649 [==============================] - 12s 7ms/sample - loss: 0.0648 - accuracy: 0.9909\n",
      "Epoch 7/10\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 0.0437 - accuracy: 0.9945\n",
      "Epoch 8/10\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 0.0302 - accuracy: 0.9988\n",
      "Epoch 9/10\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 0.0248 - accuracy: 0.9982\n",
      "Epoch 10/10\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 0.0169 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x231b35a1208>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain, ytrain, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(Xtest, ytest, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4613  Accuaracy: 0.8789\n"
     ]
    }
   ],
   "source": [
    "print('Loss: {:.4f}  Accuaracy: {:.4}'.format(score[0],score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The accuracy has increased with respect to the base model and the loss has decreased and is more accurate than the base model with the network plateaus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2 having the he_normal initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (5, 5), activation='relu', kernel_initializer='he_normal', bias_initializer='zeros'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adagrad',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1649 samples\n",
      "Epoch 1/10\n",
      "1649/1649 [==============================] - 12s 7ms/sample - loss: 3.2423 - accuracy: 0.5112\n",
      "Epoch 2/10\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 0.5679 - accuracy: 0.8187\n",
      "Epoch 3/10\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 0.3368 - accuracy: 0.9066\n",
      "Epoch 4/10\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 0.2231 - accuracy: 0.9394\n",
      "Epoch 5/10\n",
      "1649/1649 [==============================] - 12s 7ms/sample - loss: 0.1785 - accuracy: 0.9563\n",
      "Epoch 6/10\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 0.1240 - accuracy: 0.9739\n",
      "Epoch 7/10\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 0.0969 - accuracy: 0.9836\n",
      "Epoch 8/10\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 0.0776 - accuracy: 0.9873\n",
      "Epoch 9/10\n",
      "1649/1649 [==============================] - 12s 7ms/sample - loss: 0.0600 - accuracy: 0.9951\n",
      "Epoch 10/10\n",
      "1649/1649 [==============================] - 11s 7ms/sample - loss: 0.0534 - accuracy: 0.9921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x231b411cc08>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain, ytrain, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(Xtest, ytest, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5284  Accuaracy: 0.8354\n"
     ]
    }
   ],
   "source": [
    "print('Loss: {:.4f}  Accuaracy: {:.4}'.format(score[0],score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The accuracy has increased with respect to the base model and the loss has decreased and is more accurate than the base model with the network plateaus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial Neural Network (ANN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial Neural Networks (ANN) are multi-layer fully-connected neural networks that consist of an input layer, multiple hidden layers, and an output layer. They are similar to the human neurons(interconnected brain cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (410, 64, 64)\n",
      "Y shape:  (410, 1)\n"
     ]
    }
   ],
   "source": [
    "# Join a sequence of arrays along an row axis.\n",
    "x1 = np.concatenate((X[204:409], X[822:1027] ), axis=0) # from 0 to 204 is zero sign and from 205 to 410 is one sign \n",
    "z = np.zeros(205)\n",
    "o = np.ones(205)\n",
    "y1 = np.concatenate((z, o), axis=0).reshape(x1.shape[0],1)\n",
    "print(\"X shape: \" , x1.shape)\n",
    "print(\"Y shape: \" , y1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create x_train, y_train, x_test, y_test arrays\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x1, y1, test_size=0.15, random_state=42)\n",
    "number_of_train = X_train.shape[0]\n",
    "number_of_test = X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train flatten (348, 4096)\n",
      "X test flatten (62, 4096)\n"
     ]
    }
   ],
   "source": [
    "# Flatten and reshape the arrays and give it to ANN due to the dimensionality constraint as opposed to CNN\n",
    "X_train_flatten = X_train.reshape(number_of_train,X_train.shape[1]*X_train.shape[2])\n",
    "X_test_flatten = X_test .reshape(number_of_test,X_test.shape[1]*X_test.shape[2])\n",
    "print(\"X train flatten\",X_train_flatten.shape)\n",
    "print(\"X test flatten\",X_test_flatten.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train:  (4096, 348)\n",
      "x test:  (4096, 62)\n",
      "y train:  (1, 348)\n",
      "y test:  (1, 62)\n"
     ]
    }
   ],
   "source": [
    "x_train = X_train_flatten.T\n",
    "x_test = X_test_flatten.T\n",
    "y_train = Y_train.T\n",
    "y_test = Y_test.T\n",
    "print(\"x train: \",x_train.shape)\n",
    "print(\"x test: \",x_test.shape)\n",
    "print(\"y train: \",y_train.shape)\n",
    "print(\"y test: \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping The transformed data\n",
    "x_train, x_test, y_train, y_test = x_train.T, x_test.T, y_train.T, y_test.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "232/232 [==============================] - 0s 480us/step - loss: 0.6931 - accuracy: 0.5172\n",
      "Epoch 2/10\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6925 - accuracy: 0.5431\n",
      "Epoch 3/10\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6919 - accuracy: 0.5431\n",
      "Epoch 4/10\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6914 - accuracy: 0.5431\n",
      "Epoch 5/10\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.6907 - accuracy: 0.5431\n",
      "Epoch 6/10\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6904 - accuracy: 0.5431\n",
      "Epoch 7/10\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6892 - accuracy: 0.5431\n",
      "Epoch 8/10\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6885 - accuracy: 0.5431\n",
      "Epoch 9/10\n",
      "232/232 [==============================] - 0s 56us/step - loss: 0.6877 - accuracy: 0.5431\n",
      "Epoch 10/10\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6871 - accuracy: 0.5431\n",
      "116/116 [==============================] - 0s 286us/step\n",
      "Epoch 1/10\n",
      "232/232 [==============================] - 0s 488us/step - loss: 0.6934 - accuracy: 0.4784\n",
      "Epoch 2/10\n",
      "232/232 [==============================] - 0s 70us/step - loss: 0.6931 - accuracy: 0.5086\n",
      "Epoch 3/10\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6929 - accuracy: 0.5216\n",
      "Epoch 4/10\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6924 - accuracy: 0.5216\n",
      "Epoch 5/10\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6914 - accuracy: 0.5216\n",
      "Epoch 6/10\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6898 - accuracy: 0.5216\n",
      "Epoch 7/10\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6875 - accuracy: 0.5216\n",
      "Epoch 8/10\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6843 - accuracy: 0.5216\n",
      "Epoch 9/10\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6790 - accuracy: 0.5216\n",
      "Epoch 10/10\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6762 - accuracy: 0.5216\n",
      "116/116 [==============================] - 0s 151us/step\n",
      "Epoch 1/10\n",
      "232/232 [==============================] - 0s 518us/step - loss: 0.6934 - accuracy: 0.4957\n",
      "Epoch 2/10\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6925 - accuracy: 0.5129\n",
      "Epoch 3/10\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6923 - accuracy: 0.6897\n",
      "Epoch 4/10\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6920 - accuracy: 0.4957\n",
      "Epoch 5/10\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6908 - accuracy: 0.4957\n",
      "Epoch 6/10\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6891 - accuracy: 0.4957\n",
      "Epoch 7/10\n",
      "232/232 [==============================] - 0s 60us/step - loss: 0.6868 - accuracy: 0.6595\n",
      "Epoch 8/10\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6825 - accuracy: 0.5000\n",
      "Epoch 9/10\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6790 - accuracy: 0.5172\n",
      "Epoch 10/10\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.6719 - accuracy: 0.5086\n",
      "116/116 [==============================] - 0s 177us/step\n",
      "Accuracy mean: 0.47126437226931256\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the ANN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential # initialize neural network library\n",
    "from keras.layers import Dense # build our layers library specify the number of layers needed through Dense's units field\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu', input_dim = x_train.shape[1]))# Units is the size of each layer and .add method is used to add every layer to the model\n",
    "    classifier.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 10)\n",
    "accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 3)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "232/232 [==============================] - 0s 625us/step - loss: 0.6933 - accuracy: 0.4914\n",
      "Epoch 2/15\n",
      "232/232 [==============================] - 0s 65us/step - loss: 0.6929 - accuracy: 0.5431\n",
      "Epoch 3/15\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6926 - accuracy: 0.5431\n",
      "Epoch 4/15\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6925 - accuracy: 0.5431\n",
      "Epoch 5/15\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6924 - accuracy: 0.5431\n",
      "Epoch 6/15\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6923 - accuracy: 0.5431\n",
      "Epoch 7/15\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6922 - accuracy: 0.5431\n",
      "Epoch 8/15\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6921 - accuracy: 0.5431\n",
      "Epoch 9/15\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6919 - accuracy: 0.5431\n",
      "Epoch 10/15\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6918 - accuracy: 0.5431\n",
      "Epoch 11/15\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6917 - accuracy: 0.5431\n",
      "Epoch 12/15\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6916 - accuracy: 0.5431\n",
      "Epoch 13/15\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6915 - accuracy: 0.5431\n",
      "Epoch 14/15\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6914 - accuracy: 0.5431\n",
      "Epoch 15/15\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.6913 - accuracy: 0.5431\n",
      "116/116 [==============================] - 0s 181us/step\n",
      "Epoch 1/15\n",
      "232/232 [==============================] - 0s 492us/step - loss: 0.6927 - accuracy: 0.5216\n",
      "Epoch 2/15\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6912 - accuracy: 0.5216\n",
      "Epoch 3/15\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6894 - accuracy: 0.5216\n",
      "Epoch 4/15\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6855 - accuracy: 0.5216\n",
      "Epoch 5/15\n",
      "232/232 [==============================] - 0s 59us/step - loss: 0.6792 - accuracy: 0.5216\n",
      "Epoch 6/15\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6688 - accuracy: 0.5216\n",
      "Epoch 7/15\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6529 - accuracy: 0.5216\n",
      "Epoch 8/15\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6300 - accuracy: 0.5560\n",
      "Epoch 9/15\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6174 - accuracy: 0.5474\n",
      "Epoch 10/15\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.6046 - accuracy: 0.7112\n",
      "Epoch 11/15\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.5817 - accuracy: 0.7457\n",
      "Epoch 12/15\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.5487 - accuracy: 0.6422\n",
      "Epoch 13/15\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.5616 - accuracy: 0.8966\n",
      "Epoch 14/15\n",
      "232/232 [==============================] - 0s 88us/step - loss: 0.5206 - accuracy: 0.7371\n",
      "Epoch 15/15\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.4937 - accuracy: 0.8405\n",
      "116/116 [==============================] - 0s 160us/step\n",
      "Epoch 1/15\n",
      "232/232 [==============================] - 0s 555us/step - loss: 0.6932 - accuracy: 0.5043\n",
      "Epoch 2/15\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6932 - accuracy: 0.5043\n",
      "Epoch 3/15\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6929 - accuracy: 0.5043\n",
      "Epoch 4/15\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6928 - accuracy: 0.5043\n",
      "Epoch 5/15\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6923 - accuracy: 0.5043\n",
      "Epoch 6/15\n",
      "232/232 [==============================] - 0s 59us/step - loss: 0.6914 - accuracy: 0.5043\n",
      "Epoch 7/15\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6898 - accuracy: 0.5043\n",
      "Epoch 8/15\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6888 - accuracy: 0.5043\n",
      "Epoch 9/15\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6861 - accuracy: 0.5043\n",
      "Epoch 10/15\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6826 - accuracy: 0.5043\n",
      "Epoch 11/15\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6787 - accuracy: 0.5043\n",
      "Epoch 12/15\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6731 - accuracy: 0.5043\n",
      "Epoch 13/15\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6659 - accuracy: 0.5431\n",
      "Epoch 14/15\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6599 - accuracy: 0.5172\n",
      "Epoch 15/15\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6462 - accuracy: 0.6379\n",
      "116/116 [==============================] - 0s 194us/step\n",
      "Accuracy mean: 0.6063218414783478\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the ANN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential # initialize neural network library\n",
    "from keras.layers import Dense # build our layers library specify the number of layers needed through Dense's units field\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu', input_dim = x_train.shape[1]))\n",
    "    classifier.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 15)\n",
    "accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 3)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3 (Base Model) and also has the network plateau reached with an epoch value of 25 and beyon which the accuracy reamins the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "232/232 [==============================] - 0s 461us/step - loss: 0.6931 - accuracy: 0.4914\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 0s 69us/step - loss: 0.6928 - accuracy: 0.5948\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6927 - accuracy: 0.7672\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6921 - accuracy: 0.6164\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6912 - accuracy: 0.6853\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6898 - accuracy: 0.8491\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6871 - accuracy: 0.7457\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6823 - accuracy: 0.8190\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6792 - accuracy: 0.5603\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6705 - accuracy: 0.8276\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6616 - accuracy: 0.4914\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6541 - accuracy: 0.8448\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6364 - accuracy: 0.7198\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6228 - accuracy: 0.6164\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.6038 - accuracy: 0.7371\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.5853 - accuracy: 0.7586\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.5704 - accuracy: 0.7759\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.5524 - accuracy: 0.7888\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.5434 - accuracy: 0.7845\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.5375 - accuracy: 0.8319\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 0s 93us/step - loss: 0.5153 - accuracy: 0.8922\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 0s 88us/step - loss: 0.5128 - accuracy: 0.7974\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 0s 93us/step - loss: 0.4986 - accuracy: 0.8534\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.4851 - accuracy: 0.8664\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.4820 - accuracy: 0.8664\n",
      "116/116 [==============================] - 0s 328us/step\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 0s 453us/step - loss: 0.6931 - accuracy: 0.4914\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6931 - accuracy: 0.5216\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6930 - accuracy: 0.5216\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6930 - accuracy: 0.5216\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6930 - accuracy: 0.5216\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6929 - accuracy: 0.5216\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6929 - accuracy: 0.5216\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6929 - accuracy: 0.5216\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6928 - accuracy: 0.5216\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6928 - accuracy: 0.5216\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6928 - accuracy: 0.5216\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6928 - accuracy: 0.5216\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6927 - accuracy: 0.5216\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6927 - accuracy: 0.5216\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6927 - accuracy: 0.5216\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6927 - accuracy: 0.5216\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6927 - accuracy: 0.5216\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6926 - accuracy: 0.5216\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 0s 78us/step - loss: 0.6926 - accuracy: 0.5216\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6926 - accuracy: 0.5216\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6926 - accuracy: 0.5216\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6926 - accuracy: 0.5216\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 0s 88us/step - loss: 0.6926 - accuracy: 0.5216\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 0s 97us/step - loss: 0.6925 - accuracy: 0.5216\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 0s 93us/step - loss: 0.6925 - accuracy: 0.5216\n",
      "116/116 [==============================] - 0s 236us/step\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 0s 463us/step - loss: 0.6931 - accuracy: 0.5086\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6928 - accuracy: 0.4957\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6925 - accuracy: 0.4957\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6923 - accuracy: 0.4957\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6911 - accuracy: 0.4957\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6898 - accuracy: 0.5259\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6881 - accuracy: 0.4957\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6844 - accuracy: 0.4957\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6799 - accuracy: 0.5000\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6733 - accuracy: 0.5560\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6643 - accuracy: 0.5043\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6555 - accuracy: 0.5172\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6426 - accuracy: 0.6767\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6290 - accuracy: 0.5905\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6119 - accuracy: 0.6552\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.5962 - accuracy: 0.7457\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.5792 - accuracy: 0.6853\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.5585 - accuracy: 0.7974\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.5461 - accuracy: 0.7586\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.5309 - accuracy: 0.8060\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.5271 - accuracy: 0.8664\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.5118 - accuracy: 0.7198\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.5355 - accuracy: 0.8966\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.4938 - accuracy: 0.7586\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.4732 - accuracy: 0.9052\n",
      "116/116 [==============================] - 0s 185us/step\n",
      "Accuracy mean: 0.7212643623352051\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the ANN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential # initialize neural network library\n",
    "from keras.layers import Dense # build our layers library specify the number of layers needed through Dense's units field\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu', input_dim = x_train.shape[1]))\n",
    "    classifier.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 25)\n",
    "accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 3)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1 \n",
    "#### Here the activation function si cahged to elu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "232/232 [==============================] - 0s 445us/step - loss: 2.2296 - accuracy: 0.4569\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 1.6027 - accuracy: 0.4569\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 1.3018 - accuracy: 0.4569\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 1.0678 - accuracy: 0.4569\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.8742 - accuracy: 0.4569\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.7547 - accuracy: 0.4569\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 0s 75us/step - loss: 0.7012 - accuracy: 0.4655\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6926 - accuracy: 0.5431\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 0s 59us/step - loss: 0.6932 - accuracy: 0.5388\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6902 - accuracy: 0.5388\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6881 - accuracy: 0.5603\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6866 - accuracy: 0.5560\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6873 - accuracy: 0.5474\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6854 - accuracy: 0.5517\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6838 - accuracy: 0.5603\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6832 - accuracy: 0.5388\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6825 - accuracy: 0.5388\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6808 - accuracy: 0.5388\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6803 - accuracy: 0.5560\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6789 - accuracy: 0.6034\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6783 - accuracy: 0.5603\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6761 - accuracy: 0.5431\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 0s 83us/step - loss: 0.6745 - accuracy: 0.5431\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6755 - accuracy: 0.5647\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6708 - accuracy: 0.5603\n",
      "116/116 [==============================] - 0s 219us/step\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 0s 511us/step - loss: 7.3800 - accuracy: 0.5216\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 0s 74us/step - loss: 7.3800 - accuracy: 0.5216\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 7.3800 - accuracy: 0.5216\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 7.3800 - accuracy: 0.5216\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 7.3800 - accuracy: 0.5216\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 7.3800 - accuracy: 0.5216\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 7.3800 - accuracy: 0.5216\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 7.3800 - accuracy: 0.5216\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 7.3800 - accuracy: 0.5216\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 7.3800 - accuracy: 0.5216\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 7.3800 - accuracy: 0.5216\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 7.3800 - accuracy: 0.5216\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 7.3800 - accuracy: 0.5216\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 7.3800 - accuracy: 0.5216\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 7.3800 - accuracy: 0.5216\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 0s 71us/step - loss: 7.3800 - accuracy: 0.5216\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 7.3800 - accuracy: 0.5216\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 7.3800 - accuracy: 0.5216\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 0s 71us/step - loss: 7.3800 - accuracy: 0.5216\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 7.3800 - accuracy: 0.5216\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 7.3800 - accuracy: 0.5216\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 7.3800 - accuracy: 0.5216\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 7.3800 - accuracy: 0.5216\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 7.3800 - accuracy: 0.5216\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 7.3800 - accuracy: 0.5216\n",
      "116/116 [==============================] - 0s 261us/step\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 0s 447us/step - loss: 7.6460 - accuracy: 0.5043\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 7.6460 - accuracy: 0.5043\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 7.6460 - accuracy: 0.5043\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 7.6460 - accuracy: 0.5043\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 7.6460 - accuracy: 0.5043\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 7.6460 - accuracy: 0.5043\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 0s 78us/step - loss: 7.6460 - accuracy: 0.5043\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 0s 71us/step - loss: 7.6460 - accuracy: 0.5043\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 7.6460 - accuracy: 0.5043\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 7.6460 - accuracy: 0.5043\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 7.6460 - accuracy: 0.5043\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 7.6460 - accuracy: 0.5043\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 7.6460 - accuracy: 0.5043\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 7.6460 - accuracy: 0.5043\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 7.6460 - accuracy: 0.5043\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 7.6460 - accuracy: 0.5043\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 0s 74us/step - loss: 7.6460 - accuracy: 0.5043\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 7.6460 - accuracy: 0.5043\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 7.6460 - accuracy: 0.5043\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 7.6460 - accuracy: 0.5043\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 7.6460 - accuracy: 0.5043\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 0s 83us/step - loss: 7.6460 - accuracy: 0.5043\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 0s 97us/step - loss: 7.6460 - accuracy: 0.5043\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 7.6460 - accuracy: 0.5043\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 0s 88us/step - loss: 7.6460 - accuracy: 0.5043\n",
      "116/116 [==============================] - 0s 185us/step\n",
      "Accuracy mean: 0.4482758641242981\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the ANN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential # initialize neural network library\n",
    "from keras.layers import Dense # build our layers library specify the number of layers needed through Dense's units field\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'elu', input_dim = x_train.shape[1]))\n",
    "    classifier.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'elu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'elu'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 25)\n",
    "accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 3)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The accuracy of the model has decreased drastically and the accuray fo the network plateaus base model is much better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "232/232 [==============================] - 0s 477us/step - loss: 2.7045 - accuracy: 0.4569\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 1.9663 - accuracy: 0.4569\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 0s 88us/step - loss: 1.7899 - accuracy: 0.4569\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 1.6611 - accuracy: 0.4569\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 1.5498 - accuracy: 0.4569\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 0s 88us/step - loss: 1.4545 - accuracy: 0.4569\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 1.3793 - accuracy: 0.4569\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 1.3089 - accuracy: 0.4569\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 0s 88us/step - loss: 1.2493 - accuracy: 0.4569\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 1.1950 - accuracy: 0.4569\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 1.1468 - accuracy: 0.4569\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 1.1033 - accuracy: 0.4569\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 1.0641 - accuracy: 0.4569\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 1.0292 - accuracy: 0.4569\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.9987 - accuracy: 0.4569\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 0s 75us/step - loss: 0.9725 - accuracy: 0.4569\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.9466 - accuracy: 0.4569\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.9256 - accuracy: 0.4569\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.9052 - accuracy: 0.4569\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.8860 - accuracy: 0.4569\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 0s 79us/step - loss: 0.8704 - accuracy: 0.4569\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.8543 - accuracy: 0.4569\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.8399 - accuracy: 0.4569\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.8261 - accuracy: 0.4569\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.8147 - accuracy: 0.4569\n",
      "116/116 [==============================] - 0s 236us/step\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 0s 423us/step - loss: 2.0920 - accuracy: 0.5216\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 1.7296 - accuracy: 0.5216\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 1.5683 - accuracy: 0.5216\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 1.4416 - accuracy: 0.5216\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 1.3454 - accuracy: 0.5216\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 1.2716 - accuracy: 0.5216\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 1.2066 - accuracy: 0.5216\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 0s 78us/step - loss: 1.1512 - accuracy: 0.5216\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 1.1045 - accuracy: 0.5216\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 1.0615 - accuracy: 0.5216\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 1.0234 - accuracy: 0.5216\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.9895 - accuracy: 0.5216\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 0s 68us/step - loss: 0.9608 - accuracy: 0.5216\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.9337 - accuracy: 0.5216\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.9107 - accuracy: 0.5216\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.8889 - accuracy: 0.5216\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.8691 - accuracy: 0.5216\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.8516 - accuracy: 0.5216\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.8359 - accuracy: 0.5216\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.8218 - accuracy: 0.5216\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.8089 - accuracy: 0.5216\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.7968 - accuracy: 0.5216\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.7861 - accuracy: 0.5216\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.7764 - accuracy: 0.5216\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.7674 - accuracy: 0.5216\n",
      "116/116 [==============================] - 0s 181us/step\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 0s 671us/step - loss: 2.7918 - accuracy: 0.5043\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 0s 88us/step - loss: 1.7962 - accuracy: 0.5043\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 0s 93us/step - loss: 1.5817 - accuracy: 0.5043\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 1.4326 - accuracy: 0.5043\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 1.3239 - accuracy: 0.5043\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 1.2315 - accuracy: 0.5043\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 1.1600 - accuracy: 0.5043\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 0s 59us/step - loss: 1.0995 - accuracy: 0.5043\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 0s 55us/step - loss: 1.0494 - accuracy: 0.5043\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 0s 55us/step - loss: 1.0048 - accuracy: 0.5043\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 0s 59us/step - loss: 0.9670 - accuracy: 0.5043\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.9356 - accuracy: 0.5043\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 0s 101us/step - loss: 0.9057 - accuracy: 0.5043\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.8811 - accuracy: 0.5043\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 0s 101us/step - loss: 0.8608 - accuracy: 0.5043\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 0s 88us/step - loss: 0.8421 - accuracy: 0.5043\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.8264 - accuracy: 0.5043\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.8138 - accuracy: 0.5043\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.7991 - accuracy: 0.5043\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.7879 - accuracy: 0.5043\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.7776 - accuracy: 0.5043\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.7693 - accuracy: 0.5043\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.7609 - accuracy: 0.5043\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.7539 - accuracy: 0.5043\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.7461 - accuracy: 0.5043\n",
      "116/116 [==============================] - 0s 168us/step\n",
      "Accuracy mean: 0.49425287048021954\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the ANN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential # initialize neural network library\n",
    "from keras.layers import Dense # build our layers library specify the number of layers needed through Dense's units field\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'tanh', input_dim = x_train.shape[1]))\n",
    "    classifier.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'tanh'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'tanh'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 25)\n",
    "accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 3)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The accuracy of the model has decreased drastically and the accuray fo the network plateaus base model is much better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1\n",
    "#### The hinge loss (cost) function is used in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "232/232 [==============================] - 0s 964us/step - loss: 0.9569 - accuracy: 0.4741\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.9568 - accuracy: 0.5431\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.9567 - accuracy: 0.5431\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 0s 88us/step - loss: 0.9565 - accuracy: 0.5431\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 0s 89us/step - loss: 0.9561 - accuracy: 0.5431\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.9553 - accuracy: 0.5431\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.9541 - accuracy: 0.5431\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.9519 - accuracy: 0.5431\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.9498 - accuracy: 0.5431\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 0s 74us/step - loss: 0.9452 - accuracy: 0.5431\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 0s 88us/step - loss: 0.9409 - accuracy: 0.5431\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.9363 - accuracy: 0.5431\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.9311 - accuracy: 0.5431\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.9252 - accuracy: 0.5431\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 0s 78us/step - loss: 0.9211 - accuracy: 0.5431\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.9180 - accuracy: 0.5431\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.9154 - accuracy: 0.5431\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.9147 - accuracy: 0.5431\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.9138 - accuracy: 0.5431\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.9136 - accuracy: 0.5431\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.9133 - accuracy: 0.5431\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.9131 - accuracy: 0.5431\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.9130 - accuracy: 0.5431\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.9129 - accuracy: 0.5431\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.9127 - accuracy: 0.5431\n",
      "116/116 [==============================] - 0s 202us/step\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 0s 636us/step - loss: 1.0216 - accuracy: 0.5129\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 1.0215 - accuracy: 0.5216\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 1.0215 - accuracy: 0.5216\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 1.0215 - accuracy: 0.5216\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 0s 88us/step - loss: 1.0214 - accuracy: 0.5216\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 1.0214 - accuracy: 0.5216\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 1.0214 - accuracy: 0.5216\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 1.0214 - accuracy: 0.5216\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 0s 55us/step - loss: 1.0214 - accuracy: 0.5216\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 0s 55us/step - loss: 1.0214 - accuracy: 0.5216\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 0s 55us/step - loss: 1.0214 - accuracy: 0.5216\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 0s 59us/step - loss: 1.0214 - accuracy: 0.5216\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 1.0213 - accuracy: 0.5216\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 1.0213 - accuracy: 0.5216\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 1.0213 - accuracy: 0.5216\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 1.0213 - accuracy: 0.5216\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 1.0212 - accuracy: 0.5216\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 1.0212 - accuracy: 0.5216\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 1.0212 - accuracy: 0.5216\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 1.0212 - accuracy: 0.5216\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 1.0212 - accuracy: 0.5216\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 1.0211 - accuracy: 0.5216\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 1.0211 - accuracy: 0.5216\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 1.0211 - accuracy: 0.5216\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 1.0211 - accuracy: 0.5216\n",
      "116/116 [==============================] - 0s 202us/step\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 0s 475us/step - loss: 1.0044 - accuracy: 0.4741\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 1.0043 - accuracy: 0.5043\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 0s 93us/step - loss: 1.0042 - accuracy: 0.5043\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 1.0040 - accuracy: 0.5043\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 1.0035 - accuracy: 0.5043\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 1.0030 - accuracy: 0.5043\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 1.0021 - accuracy: 0.5043\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 0s 59us/step - loss: 1.0007 - accuracy: 0.5043\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 0s 59us/step - loss: 0.9984 - accuracy: 0.5043\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.9944 - accuracy: 0.5043\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.9886 - accuracy: 0.5043\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.9795 - accuracy: 0.5043\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.9716 - accuracy: 0.5043\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.9634 - accuracy: 0.5043\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.9503 - accuracy: 0.5043\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 0s 59us/step - loss: 0.9347 - accuracy: 0.5948\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.9248 - accuracy: 0.5216\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 0s 59us/step - loss: 0.9069 - accuracy: 0.6293\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 0s 59us/step - loss: 0.8954 - accuracy: 0.7328\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 0s 59us/step - loss: 0.8896 - accuracy: 0.5560\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.8805 - accuracy: 0.8405\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.8664 - accuracy: 0.6724\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.8577 - accuracy: 0.7672\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.8515 - accuracy: 0.7759\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.8442 - accuracy: 0.7845\n",
      "116/116 [==============================] - 0s 177us/step\n",
      "Accuracy mean: 0.5603448251883189\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the ANN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential # initialize neural network library\n",
    "from keras.layers import Dense # build our layers library specify the number of layers needed through Dense's units field\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu', input_dim = x_train.shape[1]))\n",
    "    classifier.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'hinge', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 25)\n",
    "accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 3)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The accuracy of the model has decreased drastically and the accuray fo the network plateaus base model is much better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "232/232 [==============================] - 0s 446us/step - loss: 0.3756 - accuracy: 0.5517\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.3734 - accuracy: 0.5431\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.3712 - accuracy: 0.5431\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.3689 - accuracy: 0.5431\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.3666 - accuracy: 0.5431\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.3642 - accuracy: 0.5431\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.3618 - accuracy: 0.5431\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.3595 - accuracy: 0.5431\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.3570 - accuracy: 0.5431\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.3544 - accuracy: 0.5431\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.3518 - accuracy: 0.5431\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.3489 - accuracy: 0.5431\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.3462 - accuracy: 0.5431\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.3433 - accuracy: 0.5431\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.3403 - accuracy: 0.5431\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.3373 - accuracy: 0.5431\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.3342 - accuracy: 0.5431\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.3311 - accuracy: 0.5431\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.3279 - accuracy: 0.5431\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.3247 - accuracy: 0.5431\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.3215 - accuracy: 0.5431\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.3181 - accuracy: 0.5431\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.3147 - accuracy: 0.5431\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 0s 59us/step - loss: 0.3113 - accuracy: 0.5431\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 0s 109us/step - loss: 0.3080 - accuracy: 0.5431\n",
      "116/116 [==============================] - 0s 194us/step\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 0s 419us/step - loss: 0.3164 - accuracy: 0.4698\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.2565 - accuracy: 0.4784\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.1811 - accuracy: 0.4784\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.0963 - accuracy: 0.4784\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.0414 - accuracy: 0.4784\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.0167 - accuracy: 0.4784\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.0073 - accuracy: 0.4784\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 0s 92us/step - loss: 0.0038 - accuracy: 0.4784\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 0s 109us/step - loss: 0.0025 - accuracy: 0.4784\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 0s 97us/step - loss: 0.0018 - accuracy: 0.4784\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 0s 97us/step - loss: 0.0015 - accuracy: 0.4784\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.0012 - accuracy: 0.4784\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.0011 - accuracy: 0.4784\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 0s 59us/step - loss: 9.3103e-04 - accuracy: 0.4784\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 0s 55us/step - loss: 8.2779e-04 - accuracy: 0.4784\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 0s 55us/step - loss: 7.4227e-04 - accuracy: 0.4784\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 0s 55us/step - loss: 6.7258e-04 - accuracy: 0.4784\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 0s 59us/step - loss: 6.1268e-04 - accuracy: 0.4784\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 0s 59us/step - loss: 5.6335e-04 - accuracy: 0.4784\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 0s 55us/step - loss: 5.1800e-04 - accuracy: 0.4784\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 0s 55us/step - loss: 4.7788e-04 - accuracy: 0.4784\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 0s 55us/step - loss: 4.4308e-04 - accuracy: 0.4784\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 0s 59us/step - loss: 4.1311e-04 - accuracy: 0.4784\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 3.8407e-04 - accuracy: 0.4784\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 0s 70us/step - loss: 3.5982e-04 - accuracy: 0.4784\n",
      "116/116 [==============================] - 0s 177us/step\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 0s 413us/step - loss: 0.3323 - accuracy: 0.4957\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.2951 - accuracy: 0.4957\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 0s 88us/step - loss: 0.2382 - accuracy: 0.4957\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.1622 - accuracy: 0.4957\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.0886 - accuracy: 0.4957\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.0392 - accuracy: 0.4957\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.0171 - accuracy: 0.4957\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.0083 - accuracy: 0.4957\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.0047 - accuracy: 0.4957\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.0032 - accuracy: 0.4957\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.0024 - accuracy: 0.4957\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.0019 - accuracy: 0.4957\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 0s 65us/step - loss: 0.0016 - accuracy: 0.4957\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.0014 - accuracy: 0.4957\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.0012 - accuracy: 0.4957\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.0011 - accuracy: 0.4957\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 9.6386e-04 - accuracy: 0.4957\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 0s 69us/step - loss: 8.6868e-04 - accuracy: 0.4957\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 7.9158e-04 - accuracy: 0.4957\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 7.2093e-04 - accuracy: 0.4957\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 6.6205e-04 - accuracy: 0.4957\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 0s 88us/step - loss: 6.1140e-04 - accuracy: 0.4957\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 5.6490e-04 - accuracy: 0.4957\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 5.2216e-04 - accuracy: 0.4957\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 4.8613e-04 - accuracy: 0.4957\n",
      "116/116 [==============================] - 0s 147us/step\n",
      "Accuracy mean: 0.5057471295197805\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the ANN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential # initialize neural network library\n",
    "from keras.layers import Dense # build our layers library specify the number of layers needed through Dense's units field\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu', input_dim = x_train.shape[1]))\n",
    "    classifier.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'kullback_leibler_divergence', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 25)\n",
    "accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 3)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The accuracy of the model has decreased drastically and the accuray fo the network plateaus base model is much better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1\n",
    "#### The epoch value is varied to 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "232/232 [==============================] - 0s 438us/step - loss: 0.6910 - accuracy: 0.5431\n",
      "Epoch 2/5\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6876 - accuracy: 0.5431\n",
      "Epoch 3/5\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.6852 - accuracy: 0.5431\n",
      "Epoch 4/5\n",
      "232/232 [==============================] - 0s 88us/step - loss: 0.6843 - accuracy: 0.5431\n",
      "Epoch 5/5\n",
      "232/232 [==============================] - 0s 93us/step - loss: 0.6795 - accuracy: 0.5431\n",
      "116/116 [==============================] - 0s 168us/step\n",
      "Epoch 1/5\n",
      "232/232 [==============================] - 0s 480us/step - loss: 0.6944 - accuracy: 0.4784\n",
      "Epoch 2/5\n",
      "232/232 [==============================] - 0s 73us/step - loss: 0.6928 - accuracy: 0.5603\n",
      "Epoch 3/5\n",
      "232/232 [==============================] - 0s 78us/step - loss: 0.6918 - accuracy: 0.4784\n",
      "Epoch 4/5\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6916 - accuracy: 0.4784\n",
      "Epoch 5/5\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6906 - accuracy: 0.4784\n",
      "116/116 [==============================] - 0s 164us/step\n",
      "Epoch 1/5\n",
      "232/232 [==============================] - 0s 506us/step - loss: 0.6932 - accuracy: 0.5043\n",
      "Epoch 2/5\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 3/5\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 4/5\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 5/5\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6932 - accuracy: 0.5043\n",
      "116/116 [==============================] - 0s 202us/step\n",
      "Accuracy mean: 0.488505740960439\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the ANN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential # initialize neural network library\n",
    "from keras.layers import Dense # build our layers library specify the number of layers needed through Dense's units field\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu', input_dim = x_train.shape[1]))\n",
    "    classifier.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 5)\n",
    "accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 3)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The accuracy of the model has decreased drastically and the accuray fo the network plateaus base model is much better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2\n",
    "#### The epoch value is set to 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "232/232 [==============================] - 0s 587us/step - loss: 0.6932 - accuracy: 0.5129\n",
      "Epoch 2/30\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6930 - accuracy: 0.5431\n",
      "Epoch 3/30\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6930 - accuracy: 0.5431\n",
      "Epoch 4/30\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6929 - accuracy: 0.5431\n",
      "Epoch 5/30\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6928 - accuracy: 0.5431\n",
      "Epoch 6/30\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6927 - accuracy: 0.5431\n",
      "Epoch 7/30\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6925 - accuracy: 0.5431\n",
      "Epoch 8/30\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6924 - accuracy: 0.5431\n",
      "Epoch 9/30\n",
      "232/232 [==============================] - 0s 65us/step - loss: 0.6923 - accuracy: 0.5431\n",
      "Epoch 10/30\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6922 - accuracy: 0.5431\n",
      "Epoch 11/30\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6921 - accuracy: 0.5431\n",
      "Epoch 12/30\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6920 - accuracy: 0.5431\n",
      "Epoch 13/30\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.6919 - accuracy: 0.5431\n",
      "Epoch 14/30\n",
      "232/232 [==============================] - 0s 78us/step - loss: 0.6918 - accuracy: 0.5431\n",
      "Epoch 15/30\n",
      "232/232 [==============================] - 0s 105us/step - loss: 0.6917 - accuracy: 0.5431\n",
      "Epoch 16/30\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6916 - accuracy: 0.5431\n",
      "Epoch 17/30\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.6915 - accuracy: 0.5431\n",
      "Epoch 18/30\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6914 - accuracy: 0.5431\n",
      "Epoch 19/30\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.6914 - accuracy: 0.5431\n",
      "Epoch 20/30\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6913 - accuracy: 0.5431\n",
      "Epoch 21/30\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6912 - accuracy: 0.5431\n",
      "Epoch 22/30\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6912 - accuracy: 0.5431\n",
      "Epoch 23/30\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6911 - accuracy: 0.5431\n",
      "Epoch 24/30\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.6910 - accuracy: 0.5431\n",
      "Epoch 25/30\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.6909 - accuracy: 0.5431\n",
      "Epoch 26/30\n",
      "232/232 [==============================] - 0s 93us/step - loss: 0.6908 - accuracy: 0.5431\n",
      "Epoch 27/30\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.6908 - accuracy: 0.5431\n",
      "Epoch 28/30\n",
      "232/232 [==============================] - 0s 93us/step - loss: 0.6907 - accuracy: 0.5431\n",
      "Epoch 29/30\n",
      "232/232 [==============================] - 0s 97us/step - loss: 0.6907 - accuracy: 0.5431\n",
      "Epoch 30/30\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6906 - accuracy: 0.5431\n",
      "116/116 [==============================] - 0s 219us/step\n",
      "Epoch 1/30\n",
      "232/232 [==============================] - 0s 438us/step - loss: 0.6929 - accuracy: 0.5216\n",
      "Epoch 2/30\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6922 - accuracy: 0.5216\n",
      "Epoch 3/30\n",
      "232/232 [==============================] - 0s 73us/step - loss: 0.6916 - accuracy: 0.5216\n",
      "Epoch 4/30\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6910 - accuracy: 0.5216\n",
      "Epoch 5/30\n",
      "232/232 [==============================] - 0s 59us/step - loss: 0.6900 - accuracy: 0.5216\n",
      "Epoch 6/30\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6893 - accuracy: 0.5216\n",
      "Epoch 7/30\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6875 - accuracy: 0.5216\n",
      "Epoch 8/30\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6858 - accuracy: 0.5216\n",
      "Epoch 9/30\n",
      "232/232 [==============================] - 0s 75us/step - loss: 0.6823 - accuracy: 0.5216\n",
      "Epoch 10/30\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6791 - accuracy: 0.5216\n",
      "Epoch 11/30\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6713 - accuracy: 0.5216\n",
      "Epoch 12/30\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6616 - accuracy: 0.5216\n",
      "Epoch 13/30\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6498 - accuracy: 0.5216\n",
      "Epoch 14/30\n",
      "232/232 [==============================] - 0s 90us/step - loss: 0.6355 - accuracy: 0.5216\n",
      "Epoch 15/30\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.6209 - accuracy: 0.5216\n",
      "Epoch 16/30\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.6009 - accuracy: 0.6940\n",
      "Epoch 17/30\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.5865 - accuracy: 0.6121\n",
      "Epoch 18/30\n",
      "232/232 [==============================] - 0s 88us/step - loss: 0.5617 - accuracy: 0.8922\n",
      "Epoch 19/30\n",
      "232/232 [==============================] - 0s 88us/step - loss: 0.5417 - accuracy: 0.7241\n",
      "Epoch 20/30\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.5140 - accuracy: 0.7802\n",
      "Epoch 21/30\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.4726 - accuracy: 0.8578\n",
      "Epoch 22/30\n",
      "232/232 [==============================] - 0s 93us/step - loss: 0.4441 - accuracy: 0.8707\n",
      "Epoch 23/30\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.4132 - accuracy: 0.8879\n",
      "Epoch 24/30\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.3769 - accuracy: 0.9009\n",
      "Epoch 25/30\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.3644 - accuracy: 0.9009\n",
      "Epoch 26/30\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.3241 - accuracy: 0.9095\n",
      "Epoch 27/30\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.3039 - accuracy: 0.9353\n",
      "Epoch 28/30\n",
      "232/232 [==============================] - 0s 59us/step - loss: 0.2844 - accuracy: 0.9267\n",
      "Epoch 29/30\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.2660 - accuracy: 0.9353\n",
      "Epoch 30/30\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.2426 - accuracy: 0.9612\n",
      "116/116 [==============================] - 0s 151us/step\n",
      "Epoch 1/30\n",
      "232/232 [==============================] - 0s 467us/step - loss: 0.6930 - accuracy: 0.5216\n",
      "Epoch 2/30\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6925 - accuracy: 0.5043\n",
      "Epoch 3/30\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6916 - accuracy: 0.5043\n",
      "Epoch 4/30\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6901 - accuracy: 0.6897\n",
      "Epoch 5/30\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6876 - accuracy: 0.8362\n",
      "Epoch 6/30\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6853 - accuracy: 0.5991\n",
      "Epoch 7/30\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6796 - accuracy: 0.6940\n",
      "Epoch 8/30\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6720 - accuracy: 0.6897\n",
      "Epoch 9/30\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6687 - accuracy: 0.7112\n",
      "Epoch 10/30\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6501 - accuracy: 0.8319\n",
      "Epoch 11/30\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6342 - accuracy: 0.7672\n",
      "Epoch 12/30\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6132 - accuracy: 0.8750\n",
      "Epoch 13/30\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.5868 - accuracy: 0.8448\n",
      "Epoch 14/30\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.5577 - accuracy: 0.8879\n",
      "Epoch 15/30\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.5258 - accuracy: 0.8793\n",
      "Epoch 16/30\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.4975 - accuracy: 0.8707\n",
      "Epoch 17/30\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.4573 - accuracy: 0.9095\n",
      "Epoch 18/30\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.4287 - accuracy: 0.9009\n",
      "Epoch 19/30\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.4083 - accuracy: 0.8836\n",
      "Epoch 20/30\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.3712 - accuracy: 0.9052\n",
      "Epoch 21/30\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.3423 - accuracy: 0.9052\n",
      "Epoch 22/30\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.3195 - accuracy: 0.9095\n",
      "Epoch 23/30\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.2984 - accuracy: 0.9267\n",
      "Epoch 24/30\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.2808 - accuracy: 0.9095\n",
      "Epoch 25/30\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.2620 - accuracy: 0.9224\n",
      "Epoch 26/30\n",
      "232/232 [==============================] - 0s 59us/step - loss: 0.2523 - accuracy: 0.9095\n",
      "Epoch 27/30\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.2298 - accuracy: 0.9353\n",
      "Epoch 28/30\n",
      "232/232 [==============================] - 0s 59us/step - loss: 0.2216 - accuracy: 0.9310\n",
      "Epoch 29/30\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.2161 - accuracy: 0.9224\n",
      "Epoch 30/30\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.2021 - accuracy: 0.9310\n",
      "116/116 [==============================] - 0s 160us/step\n",
      "Accuracy mean: 0.73563219110171\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the ANN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential # initialize neural network library\n",
    "from keras.layers import Dense # build our layers library specify the number of layers needed through Dense's units field\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu', input_dim = x_train.shape[1]))\n",
    "    classifier.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 30)\n",
    "accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 3)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The accuracy is almost same as the base model and with the increase in the epochs the accuracy is still plateaued in the same range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1\n",
    "#### Changing the optimizer to adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "232/232 [==============================] - 0s 488us/step - loss: 0.6928 - accuracy: 0.5259\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6912 - accuracy: 0.5431\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6887 - accuracy: 0.5431\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6878 - accuracy: 0.5431\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.6867 - accuracy: 0.5431\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.6805 - accuracy: 0.5431\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.6711 - accuracy: 0.5431\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 0s 97us/step - loss: 0.6643 - accuracy: 0.5431\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 0s 93us/step - loss: 0.6864 - accuracy: 0.5431\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6848 - accuracy: 0.5431\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 0s 88us/step - loss: 0.6652 - accuracy: 0.5431\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6652 - accuracy: 0.5431\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6931 - accuracy: 0.5431\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6930 - accuracy: 0.5431\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 0s 88us/step - loss: 0.6927 - accuracy: 0.5431\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6926 - accuracy: 0.5431\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6924 - accuracy: 0.5431\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6924 - accuracy: 0.5431\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6922 - accuracy: 0.5431\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 0s 88us/step - loss: 0.6921 - accuracy: 0.5431\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6919 - accuracy: 0.5431\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6917 - accuracy: 0.5431\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6916 - accuracy: 0.5431\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6915 - accuracy: 0.5431\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 0s 74us/step - loss: 0.6914 - accuracy: 0.5431\n",
      "116/116 [==============================] - 0s 177us/step\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 0s 463us/step - loss: 0.6932 - accuracy: 0.5086\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6931 - accuracy: 0.5086\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.6930 - accuracy: 0.4784\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6930 - accuracy: 0.5129\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6928 - accuracy: 0.4784\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6930 - accuracy: 0.4784\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6907 - accuracy: 0.5043\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6908 - accuracy: 0.5776\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6888 - accuracy: 0.5603\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6930 - accuracy: 0.5216\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6930 - accuracy: 0.5216\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 0s 71us/step - loss: 0.6929 - accuracy: 0.5216\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6929 - accuracy: 0.5216\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6929 - accuracy: 0.5216\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 0s 88us/step - loss: 0.6929 - accuracy: 0.5216\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6929 - accuracy: 0.5216\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6929 - accuracy: 0.5216\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.6929 - accuracy: 0.5216\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 0s 85us/step - loss: 0.6929 - accuracy: 0.5216\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.6929 - accuracy: 0.5216\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6929 - accuracy: 0.5216\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6929 - accuracy: 0.5216\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6929 - accuracy: 0.5216\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6928 - accuracy: 0.5216\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.6928 - accuracy: 0.5216\n",
      "116/116 [==============================] - 0s 210us/step\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 0s 525us/step - loss: 0.6931 - accuracy: 0.5517\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6929 - accuracy: 0.5043\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 0s 88us/step - loss: 0.6930 - accuracy: 0.5043\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 0s 114us/step - loss: 0.6920 - accuracy: 0.5474\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 0s 120us/step - loss: 0.6899 - accuracy: 0.5043\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 0s 93us/step - loss: 0.6858 - accuracy: 0.6164\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6854 - accuracy: 0.5517\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6731 - accuracy: 0.6250\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6579 - accuracy: 0.5690\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6913 - accuracy: 0.6207\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6520 - accuracy: 0.6681\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6477 - accuracy: 0.6379\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6770 - accuracy: 0.6509\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6819 - accuracy: 0.6853\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6939 - accuracy: 0.4957\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6938 - accuracy: 0.4957\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6938 - accuracy: 0.4957\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6937 - accuracy: 0.4957\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6937 - accuracy: 0.4957\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6936 - accuracy: 0.4957\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6936 - accuracy: 0.4957\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6936 - accuracy: 0.4957\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6936 - accuracy: 0.4957\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6936 - accuracy: 0.4957\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6936 - accuracy: 0.4957\n",
      "116/116 [==============================] - 0s 160us/step\n",
      "Accuracy mean: 0.4655172526836395\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the ANN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential # initialize neural network library\n",
    "from keras.layers import Dense # build our layers library specify the number of layers needed through Dense's units field\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu', input_dim = x_train.shape[1]))\n",
    "    classifier.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adadelta', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 25)\n",
    "accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 3)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The accuracy of the model has decreased drastically and the accuray fo the network plateaus base model is much better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2\n",
    "#### The optimizer used is adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "232/232 [==============================] - 0s 358us/step - loss: 0.6898 - accuracy: 0.5690\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6879 - accuracy: 0.5431\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6847 - accuracy: 0.5431\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6836 - accuracy: 0.5431\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6801 - accuracy: 0.5431\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 0s 59us/step - loss: 0.6769 - accuracy: 0.5431\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6747 - accuracy: 0.5431\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6697 - accuracy: 0.5431\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6637 - accuracy: 0.5474\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6573 - accuracy: 0.5474\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6517 - accuracy: 0.5905\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6408 - accuracy: 0.6034\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 0s 59us/step - loss: 0.6323 - accuracy: 0.5991\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6259 - accuracy: 0.5991\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6116 - accuracy: 0.6293\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - ETA: 0s - loss: 0.6986 - accuracy: 0.40 - 0s 59us/step - loss: 0.6060 - accuracy: 0.6336\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.5919 - accuracy: 0.6552\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.5784 - accuracy: 0.6983\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 0s 55us/step - loss: 0.5694 - accuracy: 0.7198\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.5643 - accuracy: 0.6724\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.5528 - accuracy: 0.7198\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 0s 59us/step - loss: 0.5464 - accuracy: 0.7931\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.5316 - accuracy: 0.7457\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.5226 - accuracy: 0.7802\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 0s 55us/step - loss: 0.5236 - accuracy: 0.7931\n",
      "116/116 [==============================] - 0s 177us/step\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 0s 358us/step - loss: 0.6936 - accuracy: 0.5043\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6930 - accuracy: 0.5216\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6929 - accuracy: 0.5216\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6929 - accuracy: 0.5216\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.6928 - accuracy: 0.5216\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6928 - accuracy: 0.5216\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 0s 88us/step - loss: 0.6927 - accuracy: 0.5216\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6928 - accuracy: 0.5216\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.6928 - accuracy: 0.5216\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6927 - accuracy: 0.5216\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.6926 - accuracy: 0.5216\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6927 - accuracy: 0.5216\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6927 - accuracy: 0.5216\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 0s 59us/step - loss: 0.6926 - accuracy: 0.5216\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 0s 65us/step - loss: 0.6926 - accuracy: 0.5216\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6926 - accuracy: 0.5216\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 0s 59us/step - loss: 0.6926 - accuracy: 0.5216\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6926 - accuracy: 0.5216\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6925 - accuracy: 0.5216\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6926 - accuracy: 0.5216\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6926 - accuracy: 0.5216\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 0s 59us/step - loss: 0.6926 - accuracy: 0.5216\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6925 - accuracy: 0.5216\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 0s 55us/step - loss: 0.6925 - accuracy: 0.5216\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6926 - accuracy: 0.5216\n",
      "116/116 [==============================] - 0s 185us/step\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 0s 339us/step - loss: 0.6944 - accuracy: 0.5043\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6932 - accuracy: 0.4957\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6932 - accuracy: 0.5043\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6932 - accuracy: 0.5043\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6932 - accuracy: 0.5043\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6932 - accuracy: 0.5043\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6932 - accuracy: 0.5043\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6932 - accuracy: 0.5043\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6932 - accuracy: 0.5043\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6932 - accuracy: 0.5043\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6932 - accuracy: 0.5043\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 0s 59us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6932 - accuracy: 0.5043\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.50 - 0s 59us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6932 - accuracy: 0.5043\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 0s 59us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6932 - accuracy: 0.5043\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6932 - accuracy: 0.5043\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "116/116 [==============================] - 0s 151us/step\n",
      "Accuracy mean: 0.47701149185498554\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the ANN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential # initialize neural network library\n",
    "from keras.layers import Dense # build our layers library specify the number of layers needed through Dense's units field\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu', input_dim = x_train.shape[1]))\n",
    "    classifier.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adagrad', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 25)\n",
    "accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 3)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The accuracy of the model has decreased drastically and the accuray fo the network plateaus base model is much better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = ['adadelta','adagrad'] \n",
    "# corresponding y axis values \n",
    "y = [0.465,0.477]  \n",
    "# plotting the points  \n",
    "plt.bar(x,y,width = 0.8, color = ['yellow', 'blue']) \n",
    "# naming the x axis \n",
    "plt.xlabel('Gradient Estimate') \n",
    "# naming the y axis \n",
    "plt.ylabel('Accuracy') \n",
    "  \n",
    "plt.title('Accuracv V/S Gradient Estimate values') \n",
    "  \n",
    "# function to show the plot \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1\n",
    "#### A layer has been removed from the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "232/232 [==============================] - 0s 454us/step - loss: 0.6944 - accuracy: 0.5000\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 0s 59us/step - loss: 0.6930 - accuracy: 0.5431\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6927 - accuracy: 0.5431\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6926 - accuracy: 0.5431\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6924 - accuracy: 0.5431\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6922 - accuracy: 0.5431\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6921 - accuracy: 0.5431\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6920 - accuracy: 0.5431\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6918 - accuracy: 0.5431\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 0s 65us/step - loss: 0.6917 - accuracy: 0.5431\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6916 - accuracy: 0.5431\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6914 - accuracy: 0.5431\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6913 - accuracy: 0.5431\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6913 - accuracy: 0.5431\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6911 - accuracy: 0.5431\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6911 - accuracy: 0.5431\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6910 - accuracy: 0.5431\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6909 - accuracy: 0.5431\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6909 - accuracy: 0.5431\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 0s 59us/step - loss: 0.6908 - accuracy: 0.5431\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6908 - accuracy: 0.5431\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6908 - accuracy: 0.5431\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6907 - accuracy: 0.5431\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6906 - accuracy: 0.5431\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6906 - accuracy: 0.5431\n",
      "116/116 [==============================] - 0s 177us/step\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 0s 421us/step - loss: 0.6978 - accuracy: 0.4353\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6932 - accuracy: 0.4698\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6931 - accuracy: 0.5216\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6931 - accuracy: 0.5216\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6931 - accuracy: 0.5216\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6931 - accuracy: 0.5216\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6931 - accuracy: 0.5216\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6930 - accuracy: 0.5216\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6930 - accuracy: 0.5216\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6930 - accuracy: 0.5216\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6930 - accuracy: 0.5216\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6930 - accuracy: 0.5216\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 0s 59us/step - loss: 0.6929 - accuracy: 0.5216\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6929 - accuracy: 0.5216\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6929 - accuracy: 0.5216\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6928 - accuracy: 0.5216\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6928 - accuracy: 0.5216\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 0s 59us/step - loss: 0.6928 - accuracy: 0.5216\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6928 - accuracy: 0.5216\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 0s 55us/step - loss: 0.6928 - accuracy: 0.5216\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6928 - accuracy: 0.5216\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6927 - accuracy: 0.5216\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6927 - accuracy: 0.5216\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6927 - accuracy: 0.5216\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 0s 55us/step - loss: 0.6927 - accuracy: 0.5216\n",
      "116/116 [==============================] - 0s 160us/step\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 0s 412us/step - loss: 0.7008 - accuracy: 0.5172\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6902 - accuracy: 0.5431\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6858 - accuracy: 0.5647\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6807 - accuracy: 0.5690\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6780 - accuracy: 0.5000\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6661 - accuracy: 0.6466\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6607 - accuracy: 0.6379\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 0s 194us/step - loss: 0.6472 - accuracy: 0.6552\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6403 - accuracy: 0.5172\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6245 - accuracy: 0.7716\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6128 - accuracy: 0.6422\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 0s 59us/step - loss: 0.6003 - accuracy: 0.7198\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 0s 59us/step - loss: 0.5833 - accuracy: 0.7198\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 0s 59us/step - loss: 0.5728 - accuracy: 0.7931\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 0s 88us/step - loss: 0.5792 - accuracy: 0.7198\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.5515 - accuracy: 0.7112\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.5350 - accuracy: 0.7716\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.5287 - accuracy: 0.8405\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.5229 - accuracy: 0.7974\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.5057 - accuracy: 0.7888\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.5006 - accuracy: 0.8103\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.4845 - accuracy: 0.8534\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.4901 - accuracy: 0.9095\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.4820 - accuracy: 0.7888\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.4671 - accuracy: 0.8836\n",
      "116/116 [==============================] - 0s 151us/step\n",
      "Accuracy mean: 0.5229885081450144\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the ANN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential # initialize neural network library\n",
    "from keras.layers import Dense # build our layers library specify the number of layers needed through Dense's units field\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu', input_dim = x_train.shape[1]))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 25)\n",
    "accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 3)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The accuracy of the model has decreased drastically and the accuray fo the network plateaus base model is much better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2\n",
    "#### The size of the input has been varied in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "232/232 [==============================] - 0s 484us/step - loss: 0.6932 - accuracy: 0.5086\n",
      "Epoch 2/30\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6930 - accuracy: 0.5431\n",
      "Epoch 3/30\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6929 - accuracy: 0.5431\n",
      "Epoch 4/30\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6927 - accuracy: 0.5431\n",
      "Epoch 5/30\n",
      "232/232 [==============================] - 0s 59us/step - loss: 0.6926 - accuracy: 0.5431\n",
      "Epoch 6/30\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6925 - accuracy: 0.5431\n",
      "Epoch 7/30\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6924 - accuracy: 0.5431\n",
      "Epoch 8/30\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6923 - accuracy: 0.5431\n",
      "Epoch 9/30\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6921 - accuracy: 0.5431\n",
      "Epoch 10/30\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6920 - accuracy: 0.5431\n",
      "Epoch 11/30\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6919 - accuracy: 0.5431\n",
      "Epoch 12/30\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6917 - accuracy: 0.5431\n",
      "Epoch 13/30\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6916 - accuracy: 0.5431\n",
      "Epoch 14/30\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6916 - accuracy: 0.5431\n",
      "Epoch 15/30\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6915 - accuracy: 0.5431\n",
      "Epoch 16/30\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6914 - accuracy: 0.5431\n",
      "Epoch 17/30\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6912 - accuracy: 0.5431\n",
      "Epoch 18/30\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6911 - accuracy: 0.5431\n",
      "Epoch 19/30\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6910 - accuracy: 0.5431\n",
      "Epoch 20/30\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6910 - accuracy: 0.5431\n",
      "Epoch 21/30\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6910 - accuracy: 0.5431\n",
      "Epoch 22/30\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6909 - accuracy: 0.5431\n",
      "Epoch 23/30\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6908 - accuracy: 0.5431\n",
      "Epoch 24/30\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6907 - accuracy: 0.5431\n",
      "Epoch 25/30\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.6907 - accuracy: 0.5431\n",
      "Epoch 26/30\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6906 - accuracy: 0.5431\n",
      "Epoch 27/30\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6905 - accuracy: 0.5431\n",
      "Epoch 28/30\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6905 - accuracy: 0.5431\n",
      "Epoch 29/30\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6905 - accuracy: 0.5431\n",
      "Epoch 30/30\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6904 - accuracy: 0.5431\n",
      "116/116 [==============================] - 0s 160us/step\n",
      "Epoch 1/30\n",
      "232/232 [==============================] - 0s 539us/step - loss: 0.6932 - accuracy: 0.4957\n",
      "Epoch 2/30\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6930 - accuracy: 0.5216\n",
      "Epoch 3/30\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6930 - accuracy: 0.5216\n",
      "Epoch 4/30\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6930 - accuracy: 0.5216\n",
      "Epoch 5/30\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6929 - accuracy: 0.5216\n",
      "Epoch 6/30\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6929 - accuracy: 0.5216\n",
      "Epoch 7/30\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6929 - accuracy: 0.5216\n",
      "Epoch 8/30\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6929 - accuracy: 0.5216\n",
      "Epoch 9/30\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6928 - accuracy: 0.5216\n",
      "Epoch 10/30\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6928 - accuracy: 0.5216\n",
      "Epoch 11/30\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6928 - accuracy: 0.5216\n",
      "Epoch 12/30\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6928 - accuracy: 0.5216\n",
      "Epoch 13/30\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6928 - accuracy: 0.5216\n",
      "Epoch 14/30\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6927 - accuracy: 0.5216\n",
      "Epoch 15/30\n",
      "232/232 [==============================] - 0s 96us/step - loss: 0.6927 - accuracy: 0.5216\n",
      "Epoch 16/30\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6927 - accuracy: 0.5216\n",
      "Epoch 17/30\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6927 - accuracy: 0.5216\n",
      "Epoch 18/30\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.6927 - accuracy: 0.5216\n",
      "Epoch 19/30\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.6927 - accuracy: 0.5216\n",
      "Epoch 20/30\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.6926 - accuracy: 0.5216\n",
      "Epoch 21/30\n",
      "232/232 [==============================] - 0s 88us/step - loss: 0.6927 - accuracy: 0.5216\n",
      "Epoch 22/30\n",
      "232/232 [==============================] - 0s 97us/step - loss: 0.6926 - accuracy: 0.5216\n",
      "Epoch 23/30\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.6926 - accuracy: 0.5216\n",
      "Epoch 24/30\n",
      "232/232 [==============================] - 0s 95us/step - loss: 0.6926 - accuracy: 0.5216\n",
      "Epoch 25/30\n",
      "232/232 [==============================] - 0s 97us/step - loss: 0.6926 - accuracy: 0.5216\n",
      "Epoch 26/30\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6926 - accuracy: 0.5216\n",
      "Epoch 27/30\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6926 - accuracy: 0.5216\n",
      "Epoch 28/30\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6926 - accuracy: 0.5216\n",
      "Epoch 29/30\n",
      "232/232 [==============================] - 0s 69us/step - loss: 0.6925 - accuracy: 0.5216\n",
      "Epoch 30/30\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6925 - accuracy: 0.5216\n",
      "116/116 [==============================] - 0s 151us/step\n",
      "Epoch 1/30\n",
      "232/232 [==============================] - 0s 450us/step - loss: 0.6930 - accuracy: 0.4871\n",
      "Epoch 2/30\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6929 - accuracy: 0.4353\n",
      "Epoch 3/30\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6923 - accuracy: 0.5043\n",
      "Epoch 4/30\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6915 - accuracy: 0.5043\n",
      "Epoch 5/30\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6906 - accuracy: 0.5043\n",
      "Epoch 6/30\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6892 - accuracy: 0.5043\n",
      "Epoch 7/30\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6864 - accuracy: 0.5043\n",
      "Epoch 8/30\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6835 - accuracy: 0.5043\n",
      "Epoch 9/30\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6794 - accuracy: 0.5043\n",
      "Epoch 10/30\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6736 - accuracy: 0.5776\n",
      "Epoch 11/30\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6723 - accuracy: 0.5129\n",
      "Epoch 12/30\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6695 - accuracy: 0.8147\n",
      "Epoch 13/30\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6561 - accuracy: 0.5086\n",
      "Epoch 14/30\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.6483 - accuracy: 0.7026\n",
      "Epoch 15/30\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.6377 - accuracy: 0.5474\n",
      "Epoch 16/30\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6280 - accuracy: 0.7371\n",
      "Epoch 17/30\n",
      "232/232 [==============================] - 0s 74us/step - loss: 0.6164 - accuracy: 0.7198\n",
      "Epoch 18/30\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6093 - accuracy: 0.5905\n",
      "Epoch 19/30\n",
      "232/232 [==============================] - 0s 93us/step - loss: 0.5888 - accuracy: 0.7198\n",
      "Epoch 20/30\n",
      "232/232 [==============================] - 0s 88us/step - loss: 0.5789 - accuracy: 0.6767\n",
      "Epoch 21/30\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.5655 - accuracy: 0.7629\n",
      "Epoch 22/30\n",
      "232/232 [==============================] - 0s 94us/step - loss: 0.5548 - accuracy: 0.7629\n",
      "Epoch 23/30\n",
      "232/232 [==============================] - 0s 93us/step - loss: 0.5399 - accuracy: 0.7500\n",
      "Epoch 24/30\n",
      "232/232 [==============================] - 0s 105us/step - loss: 0.5293 - accuracy: 0.8405\n",
      "Epoch 25/30\n",
      "232/232 [==============================] - 0s 93us/step - loss: 0.5182 - accuracy: 0.7457\n",
      "Epoch 26/30\n",
      "232/232 [==============================] - 0s 99us/step - loss: 0.5110 - accuracy: 0.8017\n",
      "Epoch 27/30\n",
      "232/232 [==============================] - 0s 93us/step - loss: 0.4962 - accuracy: 0.8103\n",
      "Epoch 28/30\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.4871 - accuracy: 0.8276\n",
      "Epoch 29/30\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.4770 - accuracy: 0.8534\n",
      "Epoch 30/30\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.4730 - accuracy: 0.8362\n",
      "116/116 [==============================] - 0s 160us/step\n",
      "Accuracy mean: 0.6005747218926748\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the ANN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential # initialize neural network library\n",
    "from keras.layers import Dense # build our layers library specify the number of layers needed through Dense's units field\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu', input_dim = x_train.shape[1]))\n",
    "    classifier.add(Dense(units = 2, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 30)\n",
    "accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 3)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1\n",
    "#### The Xavier Uniform Kernel is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "232/232 [==============================] - 0s 511us/step - loss: 0.6987 - accuracy: 0.5431\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 0s 97us/step - loss: 0.6898 - accuracy: 0.5431\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6881 - accuracy: 0.5431\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 0s 88us/step - loss: 0.6874 - accuracy: 0.5431\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 0s 86us/step - loss: 0.6865 - accuracy: 0.5431\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 0s 97us/step - loss: 0.6853 - accuracy: 0.5431\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.6843 - accuracy: 0.5431\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6827 - accuracy: 0.5431\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6808 - accuracy: 0.5431\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 0s 77us/step - loss: 0.6786 - accuracy: 0.5431\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6765 - accuracy: 0.5431\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6747 - accuracy: 0.5431\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6706 - accuracy: 0.5517\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 0s 88us/step - loss: 0.6689 - accuracy: 0.6336\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6625 - accuracy: 0.5431\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 0s 97us/step - loss: 0.6566 - accuracy: 0.5431\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6497 - accuracy: 0.5431\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 0s 101us/step - loss: 0.6383 - accuracy: 0.5560\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 0s 91us/step - loss: 0.6282 - accuracy: 0.5991\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 0s 93us/step - loss: 0.6164 - accuracy: 0.6164\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 0s 88us/step - loss: 0.6057 - accuracy: 0.6078\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.6032 - accuracy: 0.7586\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.5879 - accuracy: 0.6121\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.5697 - accuracy: 0.7241\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.5595 - accuracy: 0.7802\n",
      "116/116 [==============================] - 0s 210us/step\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 0s 501us/step - loss: 0.7362 - accuracy: 0.5216\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.7014 - accuracy: 0.4698\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 0s 93us/step - loss: 0.6842 - accuracy: 0.5345\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6511 - accuracy: 0.6250\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6279 - accuracy: 0.6940\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6048 - accuracy: 0.7371\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6037 - accuracy: 0.6681\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.5734 - accuracy: 0.6983\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.5596 - accuracy: 0.7845\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.5169 - accuracy: 0.8793\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.5021 - accuracy: 0.8621\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.4777 - accuracy: 0.9095\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.4751 - accuracy: 0.8750\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.4503 - accuracy: 0.9009\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.4282 - accuracy: 0.9224\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.4019 - accuracy: 0.9397\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.3834 - accuracy: 0.9224\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.3705 - accuracy: 0.9353\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.3595 - accuracy: 0.9181\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.3507 - accuracy: 0.9095\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.3313 - accuracy: 0.9267\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.3269 - accuracy: 0.9138\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.3040 - accuracy: 0.9095\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.2879 - accuracy: 0.9224\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.2740 - accuracy: 0.9526\n",
      "116/116 [==============================] - 0s 185us/step\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 0s 475us/step - loss: 0.7538 - accuracy: 0.4353\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6932 - accuracy: 0.5043\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 0s 78us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 0s 88us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 0s 97us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 0s 82us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "116/116 [==============================] - 0s 151us/step\n",
      "Accuracy mean: 0.6609195570151011\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the ANN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential # initialize neural network library\n",
    "from keras.layers import Dense # build our layers library specify the number of layers needed through Dense's units field\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 8, kernel_initializer = 'glorot_uniform', activation = 'relu', input_dim = x_train.shape[1]))\n",
    "    classifier.add(Dense(units = 4, kernel_initializer = 'glorot_uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'glorot_uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 25)\n",
    "accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 3)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The accuracy of the model has decreased and the accuray fo the network plateaus base model is much better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2\n",
    "#### The random Uniform Kernel is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "232/232 [==============================] - 0s 509us/step - loss: 0.6930 - accuracy: 0.5345\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6927 - accuracy: 0.5560\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6920 - accuracy: 0.5431\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6914 - accuracy: 0.6509\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6897 - accuracy: 0.5517\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6887 - accuracy: 0.5474\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6859 - accuracy: 0.8750\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6799 - accuracy: 0.5560\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6741 - accuracy: 0.7543\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6658 - accuracy: 0.8362\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6575 - accuracy: 0.5603\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6425 - accuracy: 0.8534\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 0s 59us/step - loss: 0.6249 - accuracy: 0.7112\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6063 - accuracy: 0.7543\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.5837 - accuracy: 0.8750\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.5648 - accuracy: 0.7284\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.5326 - accuracy: 0.8966\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.5020 - accuracy: 0.8534\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.4761 - accuracy: 0.8966\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.4436 - accuracy: 0.8534\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.4095 - accuracy: 0.9052\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.3911 - accuracy: 0.8793\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.3782 - accuracy: 0.9095\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.3509 - accuracy: 0.8836\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.3244 - accuracy: 0.8922\n",
      "116/116 [==============================] - 0s 227us/step\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 0s 429us/step - loss: 0.6948 - accuracy: 0.5216\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6919 - accuracy: 0.5216\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6913 - accuracy: 0.5216\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6903 - accuracy: 0.5216\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6889 - accuracy: 0.5216\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6871 - accuracy: 0.5216\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6871 - accuracy: 0.5216\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6837 - accuracy: 0.5216\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6805 - accuracy: 0.5216\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6766 - accuracy: 0.5216\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6691 - accuracy: 0.5216\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6668 - accuracy: 0.5216\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6526 - accuracy: 0.5991\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 0s 64us/step - loss: 0.6378 - accuracy: 0.5560\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6233 - accuracy: 0.5259\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6089 - accuracy: 0.6466\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.5805 - accuracy: 0.6250\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.5627 - accuracy: 0.7371\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.5360 - accuracy: 0.7716\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.5165 - accuracy: 0.7500\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.5205 - accuracy: 0.8621\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.4808 - accuracy: 0.8664\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.4724 - accuracy: 0.8190\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 0s 93us/step - loss: 0.4684 - accuracy: 0.9181\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 0s 88us/step - loss: 0.4815 - accuracy: 0.8319\n",
      "116/116 [==============================] - 0s 236us/step\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 0s 486us/step - loss: 0.6933 - accuracy: 0.4612\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 0s 71us/step - loss: 0.6932 - accuracy: 0.4957\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6931 - accuracy: 0.5388\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6932 - accuracy: 0.5043\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 0s 78us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 0s 74us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "116/116 [==============================] - 0s 177us/step\n",
      "Accuracy mean: 0.7442528704802195\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the ANN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential # initialize neural network library\n",
    "from keras.layers import Dense # build our layers library specify the number of layers needed through Dense's units field\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 8, kernel_initializer = 'random_uniform', activation = 'relu', input_dim = x_train.shape[1]))\n",
    "    classifier.add(Dense(units = 4, kernel_initializer = 'random_uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'random_uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 25)\n",
    "accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 3)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The accuracy is almost same as the base model and the netowrk plateaus models accuracy too comapred almost equally with this model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3\n",
    "#### The he_normal kernel initializer is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "232/232 [==============================] - 0s 466us/step - loss: 0.6907 - accuracy: 0.5431\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6929 - accuracy: 0.5431\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 0s 74us/step - loss: 0.6927 - accuracy: 0.5431\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6926 - accuracy: 0.5431\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6924 - accuracy: 0.5431\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6923 - accuracy: 0.5431\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6922 - accuracy: 0.5431\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6921 - accuracy: 0.5431\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6921 - accuracy: 0.5431\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6920 - accuracy: 0.5431\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6920 - accuracy: 0.5431\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.6918 - accuracy: 0.5431\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6918 - accuracy: 0.5431\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.6916 - accuracy: 0.5431\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - ETA: 0s - loss: 0.6870 - accuracy: 0.65 - 0s 72us/step - loss: 0.6916 - accuracy: 0.5431\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6916 - accuracy: 0.5431\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 0s 88us/step - loss: 0.6915 - accuracy: 0.5431\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6914 - accuracy: 0.5431\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6914 - accuracy: 0.5431\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6913 - accuracy: 0.5431\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6912 - accuracy: 0.5431\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6911 - accuracy: 0.5431\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6911 - accuracy: 0.5431\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.6910 - accuracy: 0.5431\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 0s 88us/step - loss: 0.6909 - accuracy: 0.5431\n",
      "116/116 [==============================] - 0s 242us/step\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 0s 486us/step - loss: 0.7321 - accuracy: 0.5216\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6931 - accuracy: 0.5216\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6935 - accuracy: 0.5216\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6930 - accuracy: 0.5216\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.6924 - accuracy: 0.5216\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6920 - accuracy: 0.5216\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.6927 - accuracy: 0.5216\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6921 - accuracy: 0.5216\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6920 - accuracy: 0.5216\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.6921 - accuracy: 0.5216\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 0s 93us/step - loss: 0.6919 - accuracy: 0.5216\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 0s 92us/step - loss: 0.6918 - accuracy: 0.5216\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 0s 84us/step - loss: 0.6916 - accuracy: 0.5216\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6919 - accuracy: 0.5216\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6919 - accuracy: 0.5216\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6919 - accuracy: 0.5216\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6917 - accuracy: 0.5216\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6916 - accuracy: 0.5216\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 0s 59us/step - loss: 0.6913 - accuracy: 0.5216\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6910 - accuracy: 0.5216\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6910 - accuracy: 0.5216\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6911 - accuracy: 0.5216\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6912 - accuracy: 0.5216\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6906 - accuracy: 0.5216\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6901 - accuracy: 0.5216\n",
      "116/116 [==============================] - 0s 244us/step\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 0s 522us/step - loss: 0.7789 - accuracy: 0.5302\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 0s 76us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 0s 88us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 0s 59us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 0s 88us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 0s 88us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 0s 93us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 0s 93us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 0s 93us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 0s 80us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 0s 72us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 0s 67us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 0s 65us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 0s 63us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 0s 59us/step - loss: 0.6931 - accuracy: 0.5043\n",
      "116/116 [==============================] - 0s 160us/step\n",
      "Accuracy mean: 0.4482758641242981\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the ANN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential # initialize neural network library\n",
    "from keras.layers import Dense # build our layers library specify the number of layers needed through Dense's units field\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 8, kernel_initializer = 'he_normal', activation = 'relu', input_dim = x_train.shape[1]))\n",
    "    classifier.add(Dense(units = 4, kernel_initializer = 'he_normal', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'he_normal', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 25)\n",
    "accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 3)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The accuracy of the model has decreased drastically and the accuray fo the network plateaus base model is much better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = ['glorot_uniform','random_uniform','he_normal'] \n",
    "# corresponding y axis values \n",
    "y = [0.660,0.744,0.448]  \n",
    "# plotting the points  \n",
    "plt.bar(x,y,width = 0.8, color = ['red', 'blue','green']) \n",
    "# naming the x axis \n",
    "plt.xlabel('Network Initializer') \n",
    "# naming the y axis \n",
    "plt.ylabel('Accuracy') \n",
    "  \n",
    "plt.title('Accuracv V/S Network Initializer values') \n",
    "  \n",
    "# function to show the plot \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "### 1) The Deep Learning models of the Convolution Neural Network(CNN) and the Artificial Neural network (ANN) were implemetned on the Hand Sign Image data set;\n",
    "### 2) The different parameters involved while designing a Deep Learning model were understood and the values were altered accordingly to see the accuracy;\n",
    "### 3) The Base models of the Convolutional Neural Network and the Artificial Neural Network both had almost the same accuracy\n",
    "### 4) The concept of network plateau was explored and the paraemters of the model were varied in order to see their accuracy with the model having the newtork plateau\n",
    "### 5)It was also observed that some models outperformed and some models were below the base model in both CNN and ANN in terms of the accuracy when the parameters were altered\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contributions\n",
    "### Percentage of code contributed individually: 60%\n",
    "### Percentage of code borrowed from external sources: 40%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citations:\n",
    "### The sources majorly used for the project are as follows:\n",
    "### 1)https://www.kaggle.com/lbronchal/cnn-with-different-seeds-accuracy-99 \n",
    "### 2)https://keras.io/initializers/\n",
    "### 3)https://github.com/nikbearbrown/Deep_Learning\n",
    "### 4)https://www.kaggle.com/ardamavi/sign-language-digits-dataset/kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### License:\n",
    "### Copyright 2020 Samartha Swaroop Girish\n",
    "\n",
    "### Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "### The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "### THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fin."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
